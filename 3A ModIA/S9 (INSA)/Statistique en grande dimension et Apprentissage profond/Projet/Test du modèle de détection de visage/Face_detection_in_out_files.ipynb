{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 640x480 (no detections), 57.8ms\n",
      "Speed: 4.0ms preprocess, 57.8ms inference, 1.8ms postprocess per image at shape (1, 3, 640, 480)\n",
      "\n",
      "0: 640x512 1 Face, 43.8ms\n",
      "Speed: 1.2ms preprocess, 43.8ms inference, 1.3ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 448x640 10 Faces, 37.7ms\n",
      "Speed: 1.0ms preprocess, 37.7ms inference, 0.5ms postprocess per image at shape (1, 3, 448, 640)\n",
      "\n",
      "0: 640x512 1 Face, 38.9ms\n",
      "Speed: 1.7ms preprocess, 38.9ms inference, 0.4ms postprocess per image at shape (1, 3, 640, 512)\n",
      "\n",
      "0: 480x640 (no detections), 44.0ms\n",
      "Speed: 1.4ms preprocess, 44.0ms inference, 0.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "Crops des visages détectés sauvegardés dans ./OUT (TEST)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "import math\n",
    "import os\n",
    "\n",
    "# Charger le modèle YOLO\n",
    "model = YOLO(\"yolov8n_100e.pt\")  # Mettre à jour avec le chemin vers ton modèle personnalisé\n",
    "\n",
    "# Classes des objets (dans ton cas, \"visage\")\n",
    "classNames = [\"visage\"]\n",
    "\n",
    "# Dossiers d'images\n",
    "input_folder = \"./IN (TEST)\"  # Chemin du dossier contenant les images\n",
    "output_folder = \"./OUT (TEST)\"  # Chemin du dossier où les crops seront sauvegardés\n",
    "\n",
    "# Assurer que le dossier de sortie existe\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Fonction pour traiter chaque image et sauvegarder les crops\n",
    "def process_images(image_path, output_folder, image_name):\n",
    "    img = cv2.imread(image_path)\n",
    "    \n",
    "    # Effectuer la détection\n",
    "    results = model(img)\n",
    "    \n",
    "    # Parcourir les résultats de la détection\n",
    "    for r in results:\n",
    "        boxes = r.boxes\n",
    "\n",
    "        face_count = 0\n",
    "        for box in boxes:\n",
    "            # Extraire les coordonnées de la bounding box\n",
    "            x1, y1, x2, y2 = box.xyxy[0]\n",
    "            x1, y1, x2, y2 = int(x1), int(y1), int(x2), int(y2)\n",
    "\n",
    "            # Confiance et classe\n",
    "            confidence = math.ceil((box.conf[0] * 100)) / 100\n",
    "            cls = int(box.cls[0])\n",
    "\n",
    "            if confidence > 0.5 and classNames[cls] == \"visage\":  # Seulement si c'est un visage\n",
    "                # Créer un crop du visage\n",
    "                face_crop = img[y1:y2, x1:x2]\n",
    "                \n",
    "                # Sauvegarder le crop dans un fichier\n",
    "                face_filename = f\"{image_name}_face_{face_count}.jpg\"\n",
    "                cv2.imwrite(os.path.join(output_folder, face_filename), face_crop)\n",
    "                face_count += 1\n",
    "\n",
    "# Parcourir toutes les images dans le dossier d'entrée\n",
    "for image_name in os.listdir(input_folder):\n",
    "    if image_name.endswith((\".jpg\", \".png\", \".jpeg\")):  # Filtrer les formats d'image\n",
    "        image_path = os.path.join(input_folder, image_name)\n",
    "        process_images(image_path, output_folder, image_name.split('.')[0])\n",
    "\n",
    "print(\"Crops des visages détectés sauvegardés dans\", output_folder)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_yolo",
   "language": "python",
   "name": "env_yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
