---
title: "Projet_EMS"
output:
  pdf_document: default
  html_document: default
date: "2023-09-29"
editor_options: 
  markdown: 
    wrap: 72
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=F, error=F,warning=F}
library(corrplot)
library(tidyverse)
library(gridExtra)
library(reshape2)
library(ggplot2)
library(FactoMineR)
```

# Statistiques descriptives

Le jeu de données comprend $984$ mesures des emissions de polluants
atmosphériques tous secteurs d'activités confondues des EPCI
(Etablissements Publics de Coopération Intercommunale) de la région
Occitanie de 2014 à 2019.

Chaque mesure est décrite par les variables qualitatives suivantes : +
*lib_epci* : son nom + *code_epci* : son code d'identification +
*nomdepart* : son (ses) département(s) d'appartenance + *TypeEPCI* : CC
(communauté de commune), CA (communauté d'agglomération), Métrople et CU
(communauté urbaine) + *annee_inv* : l'année de mesure

Et par les variables quantitatives suivantes : + *nox_kg* : oxyde
d'azote en kg + *so2_kg* : oxyde de soufre en kg + *pm10_kg* :
particules en suspension dans l'air de diamètre inférieur à 10 µm +
*pm25_kg* : particules en suspension dans l'air de diamètre inférieur à
2.5 µm + *co_kg* : monoxyde de carbone + *c6h6_kg* : benzène + *nh3_kg*
: Ammoniac + *ges_teqco2* : gaz à effet de serre + *ch4_t* : méthane +
*co2_t* : dioxyde de carbone + *n2o_t* : protoxyde d'azote + *latit* :
sa latitude + *longit* : sa longitude

```{r}
Data = read.csv("Data-projetmodIA-2324.csv", header = TRUE)
```

```{r}
head(Data)
```

```{r, echo = FALSE}
# TODO : pour moi ici les as.factor ne doivent être fait que sur les variables qualitatives

Data$TypeEPCI=as.factor(Data$TypeEPCI)
Data$annee_inv=as.factor(Data$annee_inv)
Data$nomdepart=as.factor(Data$nomdepart)
Data$lib_epci=as.factor(Data$lib_epci)
Data$Ardèche = as.factor(Data$Ardèche)
Data$Ariège = as.factor(Data$Ariège)
Data$Aude = as.factor(Data$Aude)
Data$Aveyron = as.factor(Data$Aveyron)
Data$Gard = as.factor(Data$Gard)
Data$Haute.Garonne = as.factor(Data$Haute.Garonne)
Data$Gers = as.factor(Data$Gers)
Data$Hérault = as.factor(Data$Hérault)
Data$Landes = as.factor(Data$Landes)
Data$Lot = as.factor(Data$Lot)
Data$Lot.et.Garonne = as.factor(Data$Lot.et.Garonne)
Data$Lozère = as.factor(Data$Lozère)
Data$Pyrénées.Atlantiques = as.factor(Data$Pyrénées.Atlantiques)
Data$Hautes.Pyrénées = as.factor(Data$Hautes.Pyrénées)
Data$Pyrénées.Orientales = as.factor(Data$Pyrénées.Orientales)
Data$Tarn = as.factor(Data$Tarn)
Data$Tarn.et.Garonne = as.factor(Data$Tarn.et.Garonne)
Data$Vaucluse = as.factor(Data$Vaucluse)
```

```{r, echo = FALSE}
summary(Data)
```

```{r}
attributes(Data)
```

```{r str}
str(Data)
```

## Analyse unidimentionnelle

```{r}
Datalog = log(Data[,4:14]) #à justifier
head(Datalog)
```

###Quantitative

```{r}
library(reshape2)
ggplot(melt(Datalog),aes(x=variable,y=value))+geom_boxplot()
```

###Qualitative

```{r}
barplot(table(Data$TypeEPCI))
```

```{r}
barplot(table(Data$annee_inv))
```

```{r}
plot(ecdf(Datalog$so2_kg)) #,xlim = c(320,400)
```

# PCA

On fait une ACP. lol xD

```{r}
Datalog = Data[1:16]
Datalog[,4:14] = log(Datalog[,4:14])

ACPpolluants <- PCA(Datalog, scale.unit = TRUE, ncp = 11, quali.sup = c(1,2,3,15,16), graph = FALSE)  # Utilisation de scale.unit = TRUE pour standardiser les données.

plot(ACPpolluants, choix="ind",invisible = "quali", habillage = 15, cex = 0.1, legends = NULL)  #

#plot.PCA(ACPpolluants, invisible = "quali", habillage = 2, legends = c("ind"))

#dist_to_center <- apply(ACPpolluants$ind$coord, 1, function(x) sum(x^2))

# Identifier les individus considérés comme des outliers (par exemple, les individus au-delà du seuil de 95e percentile)
#outlier_threshold <- quantile(dist_to_center, 1-12/985) #On garde les 12 valeurs abberantes on identifie 2 outliers
#outliers <- which(dist_to_center > outlier_threshold)

```

```{r}
layout(matrix(1:2,1,2))
plot(ACPpolluants, choix="ind",invisible = "quali", habillage = 15, cex = 0.1, legends = NULL) 
plot(ACPpolluants, choix="ind",invisible = "quali", habillage = 3, cex = 0.1, legends = NULL)  #

```

```{r}
layout(matrix(1:2,1,2))
barplot(ACPpolluants$eig[,"cumulative percentage of variance"],names.arg=paste("Dim",1:11,sep="."))
abline(a = 90, b=0, col="red", lty=2, lwd=3)
barplot(ACPpolluants$eig[,"percentage of variance"], names.arg=paste("Dim",1:11,sep="."))
```

```{r}
Datalog = Data[1:16]
Datalog[,4:14] = log(Datalog[,4:14])
Data_final <- subset(Datalog, lib_epci != "Toulouse Métropole") #, "CC Pays de Nay"))
Data_final <- subset(Data_final, lib_epci != "CC Pays de Nay")

print(nrow(Data_final))
summary(Data_final)
```

```{r}
ggplot(melt(Data_final[4:14]),aes(x=variable,y=value))+geom_boxplot()
```

```{r}
ACPpolluants <- PCA(Data_final, scale.unit = TRUE, ncp = 3, quali.sup = c(1,2,3,15,16), graph = FALSE)  # Utilisation de scale.unit = TRUE pour standardiser les données.
# on degage la dimension 3
plot(ACPpolluants, choix="ind",invisible = "quali", habillage = 15, cex = 0.1, legends = NULL) 
plot(ACPpolluants, choix="ind",invisible = "quali", habillage = 3, cex = 0.1, legends = NULL) 

plot(ACPpolluants, choix="var",invisible = "quali", habillage = 15, legends = NULL, axes =c(1,2)) 
plot(ACPpolluants, choix="ind",invisible = "quali", habillage = 15, cex = 0.3, legends = NULL, axes =c(1,3)) 



```

```{r}
f1 = fviz_contrib(ACPpolluants, choice="var", axes=1, color = "black" ,fill="turquoise4")
f2 = fviz_contrib(ACPpolluants, choice="var", axes=2, color ="black", fill = "#3EBB00")
f3 = fviz_contrib(ACPpolluants, choice="var", axes=3, color ="black", fill = "#E6E600")
plot_grid(f1,f2,f3)
```

```{r}

```

```{r}
ACPpolluants$var
```

```{r}
ggplot(Datalog,aes(x=annee_inv))+
  geom_bar()
```

```{r}
corrplot(cor(Data_final[4:14]), method="ellipse")
```

Test rien à voir avec le sujet

```{r}
plot(Data$nox_kg, type = "l")
plot(log(Data$nox_kg), type = "l")
```

```{r}
ggplot(Data, aes(nox_kg)) + 
  stat_ecdf(geom = "step")+xlab("Variable Alcool")+
  ylab("")+ggtitle("Fonction de répartition empirique")+
  geom_hline(yintercept=0, linetype="dashed")+geom_hline(yintercept=1, linetype="dashed")

ggplot(Datalog, aes(nox_kg)) + 
  stat_ecdf(geom = "step")+xlab("Variable Alcool")+
  ylab("")+ggtitle("Fonction de répartition empirique")+
  geom_hline(yintercept=0, linetype="dashed")+geom_hline(yintercept=1, linetype="dashed")
```

```{r}
g1<-ggplot(Data,aes(x=nox_kg))+geom_histogram(bins=15,color="black", fill="white")+
  ggtitle("Histo. des effectifs")+ylab("Frequency")+xlab("Alcool")
g2<-ggplot(Datalog,aes(x=nox_kg))+geom_histogram(bins=15,color="black", fill="white")+
  ggtitle("Histo. des effectifs")+ylab("Frequency")+xlab("Alcool")
grid.arrange(g1,g2,ncol=2)
```

Clustering

```{r}
Data_poll = Data[,4:14]

Data_poll

reskmeans<-kmeans(scale(Datalog[,4:14]), 7, nstart = 5)

table(reskmeans$cluster)

fviz_cluster(reskmeans,data=Datalog[,4:14],type="norm",labelsize=0)
```





## LDA
### Exploration et prédiction du dépassement d'émission de méthane de 1000 t par an

On veut prédire si la variable ch4_t dépasse le seuil de 1000 t par an. Nous allons alors créer une nouvelle variable y avec deux levels : 'above' si ch4_t > 1000 et 'below' sinon.

```{r}
y = as.factor(Data$ch4_t < 1000)
levels(y) = c('above','below')
```

Pour la suite, nous remplaçons la colonne ch4_t, dans les données modifiées, par y.

```{r}
DataLDA = Datalog[,4:14]
DataLDA$ch4_t = y
```

```{r}
DataLDA
```
Pour préciser ce que LDA vise à faire, nous nous mettons d'accord que LDA est une PCA appliquée sur les classes des centroides, avec le métrique Mahalanobis (i.e. les données sont tout d'abord sphérées). La LDA appliquée sur 2 nouveaux individus (les 2 centroides des 2 classes : 'above' et 'below') dans un espace de 11 variables.
Nous cherchons à visualiser les 2 classes avec une PCA représentation pour les données log-modifiées.
```{r}
ACPLDA <- PCA(DataLDA, scale.unit = TRUE, quali.sup = c(9), graph=FALSE)
summary(ACPLDA)
plot(ACPLDA, choix="ind", invisible="quali", habillage=9, label="none")
```
Nous nous rappelons que l'hypothèse qui se pose pour une LDA est que les individus d'une même classe sont tirées depuis un Gaussien commun avec une même matrice de covariance. En regardant les 2 nuages des points sur le PCA plot, elles sont de la forme assez éllipsoide et uniforme, qui permet de dire que les individus sont bien d'un même Gaussien. De plus, la deuxième dimension est expliquée ci-dessus proportionnelle à l'émission en ch4, donc quand on observe les 2 nuages, celle représentante la classe 'above' est au-dessus (i.e. supérieure) de la 'below', totalement cohérent à ce qu'on a trouvé dans la PCA.  
De plus, on se rend compte que la projection des individus dans le sous-espace 2D explique à peu près 90% de la variance donc on ne perd pas beaucoup d'informations.

Pour la prédiction, nous divisons le jeu de données en deux : un train set de 70% des données et un test set de 30% des données.

```{r}
train =  
test =
```

## ANOVA à 2 facteurs
Analyser la relation entre l'émission des gas à effets de serrre et le type EPCI et l'année.  
L'émission des gas à effet de serre pour chaque modalité croisée du typeEPCI et l'année.
```{r}
table(Data$TypeEPCI,Data$annee_inv)
Data %>%
  group_by(TypeEPCI,annee_inv) %>%
  rstatix::get_summary_stats(ges_teqco2, type="mean_sd")
```

```{r}
ggplot(Data,aes(x=annee_inv,y=ges_teqco2,fill=TypeEPCI)) + geom_boxplot()
ggplot(Data,aes(x=TypeEPCI,y=ges_teqco2,fill=annee_inv)) + geom_boxplot()
```

Interaction plot
```{r}
#interaction.plot(Data$TypeEPCI, Data$annee_inv, Data$ges_teqco2,
 #                main="interaction plot", xlab="TypeEPCI", ylab="ges_teqco2",
  #               trace.label ="annee_inv")
interaction.plot(Data$annee_inv, Data$TypeEPCI, Data$ges_teqco2,
                 main="interaction plot", ylab="TypeEPCI", xlab="ges_teqco2",
                 trace.label ="annee_inv")
```
Les droites du plot de l'intéraction sont parallèles donc on peut dire qu'il n'y a pas d'effet d'intéraction.

```{r}
anova.complet = lm(ges_teqco2~TypeEPCI * annee_inv, data=Data)
summary(anova.complet)
```
Commentaire :
Le coefficient de détermination R² est à 0.67, l'ajustement n'est pas mal mais pas trop bon.
On accepte la nullité de tous les paramètres de l'effet différentiel de l'année et de l'effet d'intéraction. On peut dire que les différentes années jouent le même rôle

```{r}
anova.additif= lm(ges_teqco2~TypeEPCI + annee_inv, data=Data)
anova(anova.additif, anova.complet)
```

```{r}
anova(lm(ges_teqco2~annee_inv, data=Data), anova.additif)
anova(lm(ges_teqco2~TypeEPCI, data=Data), anova.additif)
```

```{r}
anova(lm(ges_teqco2~TypeEPCI, data=Data), anova.complet)
```

```{r}
anova(lm(ges_teqco2~1, data=Data), lm(ges_teqco2~TypeEPCI, data=Data))
```







## Modèle linéaire généralisé

Nous allons dans cette section tenter d'expliquer le dépassement d'émission de méthane de $1000t$ par an en fonction de l'ammoniac, le protoxyde d'azote, le type d'EPCI et l'année par un modèle linéaire généralisé.

```{r, echo=F, eval=F}
library(bestglm)

# TODO : à remettre en commun

# Ici je refais la sélection des variables (je ne leur applique ni log ni scale)
Data_mlg = read.csv("Data-projetmodIA-2324.csv", header = TRUE)
Data_mlg$code_epci = as.factor(Data_mlg$code_epci)
Data_mlg$lib_epci = as.factor(Data_mlg$lib_epci)
Data_mlg$annee_inv = as.factor(Data_mlg$annee_inv)
Data_mlg$TypeEPCI = as.factor(Data_mlg$TypeEPCI)

# On prend les données quantitatives log
Data_mlg$nh3_kg = log(Data_mlg$nh3_kg)
Data_mlg$n2o_t = log(Data_mlg$n2o_t)

# Je retire les outliers
Data_mlg <- subset(Data_mlg, lib_epci != "Toulouse Métropole") #, "CC Pays de Nay"))
Data_mlg <- subset(Data_mlg, lib_epci != "CC Pays de Nay")

summary(Data_mlg)

# Je garde les variables qui m'intéresse
Data_mlg <- Data_mlg[c(3,10,12,14,15)]

summary(Data_mlg)
```

On crée la nouvelle variable booléenne, valant 1 si le taux de méthane (\code{ch4_t}) est supérieur à $1000t$, 0 sinon.

```{r, echo=T, eval=T}
# Je crée une nouvelle variable qualitative (celle qui traduit méthane > 1000t)
Data_mlg$dep_met_1000 <- as.factor(as.numeric(Data_mlg$ch4_t>1000))

summary(Data_mlg)

# Je retire la variable quantitative ch4_t
Data_mlg <- Data_mlg[c(1,2,4,5,6)]

summary(Data_mlg)
head(Data_mlg)
```

La variable \code{dep_met_1000} étant binaire, nous allons utiliser la régression logistique.

Dans un premier temps on crée le modèle complet avec interaction, modèle que l'on note $(\mathcal{M}_{GL_{1}})$ :

$$
\begin{equation*}
(\text{M}_{GL_{1}}) : 

\begin{cases}
\text{dep_met_1000}_i \sim \mathcal{B}(\pi_\theta(x_i)) \\

\\

\text{logit}[\pi_\theta(x_i)] = \mu  +  \theta_1\cdot\text{nh3_kg}_i  + \theta_2\cdot\text{n2o_t}_i  +  \gamma\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i  \\ 
  + (\beta_1  +  \beta_2\cdot\text{nh3_kg}_i ~ + \beta_3\cdot\text{n2o_t}_i + \beta_4\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}} \\
  + \sum_{k=1}^5 (\delta_{1k}  +  \delta_{2k}\cdot\text{nh3_kg}_i ~ + \delta_{3k}\cdot\text{n2o_t}_i + \delta_{4k}\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{annee}_i = 2014 + k} \\
  + \sum_{k=1}^5 (\kappa_{1k}  +  \kappa_{2k}\cdot\text{nh3_kg}_i ~ + \kappa_{3k}\cdot\text{n2o_t}_i + \kappa_{4k}\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i)\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}}\cdot\mathbb{1}_{\text{annee}_i = 2014 + k} \\

\end{cases}

\end{equation*}
$$

```{r, echo=T, eval=T}
modelcompletinter = glm(dep_met_1000~(.)^2, data=Data_mlg, family=binomial(link = "logit"))
summary(modelcompletinter)
```

On voit que beaucoup de variables ont une pvaleur > 0.05. On va alors s'intéresser à la simplification du modèle.

```{r, echo=T, eval=T}
pseudoR2 = 1 - modelcompletinter$deviance/modelcompletinter$null.deviance
pseudoR2
```

Le $\text{pseudoR}^2$ vaut 0.73, ce qui est une valeur correcte.

```{r, echo = T, eval = F}
# Les bestglm ne fonctionnent pas
#bestglm(Data_mlg,family=binomial,IC="AIC")
#bestglm(Data_mlg,family=binomial,IC="BIC")
```

Ici, les fonctions \code{bestglm} ne fonctionnent pas, nous n'avons donc pas reporté leurs sorties dans le rapport.

```{r, echo = T, eval = T}
# Quelque chose semble ne pas fonctionner dans les step.backward
step.backward = step(modelcompletinter) # AIC
step.backward = step(modelcompletinter, direction="backward",k=log(nrow(Data_mlg))) # BIC
```

Le critère $AIC$ conserve le modèle sans l'interaction annee_inv:TypeEPCI, modèle que l'on note $(\text{M}_{GL_{2}})$.
Le critère $BIC$ conserve le modèle avec les variables nh3_kg, n2o_t, TypeEPCI, nh3_kg:n2o_t, modèle que l'on note $(\text{M}_{GL_{3}})$.


$$
\begin{equation*}
(\text{M}_{GL_{2}}) : 

\begin{cases}
\text{dep_met_1000}_i \sim \mathcal{B}(\pi_\theta(x_i)) \\

\\

\text{logit}[\pi_\theta(x_i)] = \mu  +  \theta_1\cdot\text{nh3_kg}_i  + \theta_2\cdot\text{n2o_t}_i  +  \gamma\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i  \\ 
  + (\beta_1  +  \beta_2\cdot\text{nh3_kg}_i ~ + \beta_3\cdot\text{n2o_t}_i  + \beta_4\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}} \\
  + \sum_{k=1}^5 (\delta_{1k}  +  \delta_{2k}\cdot\text{nh3_kg}_i ~ + \delta_{3k}\cdot\text{n2o_t}_i + \delta_{4k}\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{annee}_i = 2014 + k} \\

\end{cases}

\end{equation*}
$$


$$
\begin{equation*}
(\text{M}_{GL_{3}}) : 

\begin{cases}
\text{dep_met_1000}_i \sim \mathcal{B}(\pi_\theta(x_i)) \\

\\

\text{logit}[\pi_\theta(x_i)] = \mu  +  \theta_1\cdot\text{nh3_kg}_i  + \theta_2\cdot\text{n2o_t}_i  +  \gamma\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i  \\ 
  + (\beta_1  +  \beta_2\cdot\text{nh3_kg}_i ~ + \beta_3\cdot\text{n2o_t}_i + \beta_4\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}} \\

\end{cases}

\end{equation*}

$$


```{r, echo = T, eval = T}
# Modèle 2
model2 = glm(dep_met_1000~annee_inv + nh3_kg + n2o_t + TypeEPCI + annee_inv:nh3_kg + 
    annee_inv:n2o_t + nh3_kg:n2o_t + nh3_kg:TypeEPCI + n2o_t:TypeEPCI ,data=Data_mlg, family=binomial(link = "logit"))
summary(model2)
```

On teste le sous-modèle $(\text{M}_{GL_{2}})$ par rapport au modèle complet avec interactions $(\text{M}_{GL_{1}})$.

```{r, echo = T, eval = T}
anova(model2, modelcompletinter, test="Chisq")
```

La pvaleur est >>0.05, on peut donc conserver le modèle $(\text{M}_{GL_{2}})$ au risque 5%.

```{r, echo = T, eval = T}
pseudoR2 = 1 - modelinterred$deviance/modelinterred$null.deviance
pseudoR2
```

Le $\text{pseudoR}^2$ vaut 0.72, ce qui reste une valeur correcte (très légèrement en dessous du $\text{pseudoR}^2$ du modèle complet avec interaction).

```{r, echo = T, eval = T}
# Modèle 3
model3 = glm(dep_met_1000 ~ nh3_kg + n2o_t + TypeEPCI + nh3_kg:n2o_t,data=Data_mlg, family=binomial(link = "logit"))
summary(model3)
```

```{r, echo = T, eval = T}
anova(model3, modelcompletinter, test="Chisq")
```

Cependant, le test du sous-modèle $(\text{M}_{GL_{3}})$ vis-à-vis du modèle complet $(\text{M}_{GL_{1}})$ renvoie une pvaleur << 0.05.
On rejette donc le modèle $(\text{M}_{GL_{3}})$ au risque $5\%$.

```{r, echo=F, eval=F}
# A VOIR SI L'ETUDE DU MODELE ADDITIF EST PERTINENTE, JE METS POUR L'INSTANT CETTE SECTION DE CODE AINSI QUE LA SUICANTE EN "echo=F, eval=F"

modelcompletadd = glm(dep_met_1000~. ,data=Data_mlg, family=binomial(link = "logit"))
summary(modelcompletinter)
```

```{r, echo=F, eval=F}
step.backward = step(modelcompletadd) # AIC
step.backward = step(modelcompletadd, direction="backward",k=log(nrow(Data_mlg))) # BIC
```