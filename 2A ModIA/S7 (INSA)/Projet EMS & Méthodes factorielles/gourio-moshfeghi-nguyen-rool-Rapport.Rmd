---
title: "Projet d'étude : Analyse de données & Éléments de modélisation statistique"
output:
  pdf_document: default
  html_document: default
date: "2023-09-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=F, error=F,warning=F}
library(corrplot)
#library(tidyverse)
library(gridExtra)
library(reshape2)
library(ggplot2)
library(FactoMineR)
library(leaps)
library(bestglm)
```

```{r, include=FALSE}
library(mclust)
library(cluster)
library(factoextra)
library(FactoMineR)
library(ppclust)
library(reticulate)
library(ggplot2)
library(reshape)
library(corrplot)
library(gridExtra)
library(circlize)
library(viridis)
library(reshape2)
library(klaR)
library(MASS)
```
# Statistiques descriptives

Le jeu de données comprend $984$ mesures des émissions de polluants atmosphériques tous secteurs d’activités confondues des EPCI (Etablissements Publics de Coopération Intercommunale) de la région Occitanie de 2014 à 2019.

Chaque mesure est décrite par les variables qualitatives suivantes :
+ *lib_epci* : son nom
+ *code_epci* : son code d’identification
+ *nomdepart* : son (ses) département(s) d’appartenance
+ *TypeEPCI* : CC (communauté de commune), CA (communauté d’agglomération), Métrople et CU (communauté urbaine)
+ *annee_inv* : l'année de mesure

Et par les variables quantitatives suivantes : 
+ *nox_kg* : oxyde d’azote en kg
+ *so2_kg* : oxyde de soufre en kg
+ *pm10_kg* : particules en suspension dans l’air de diamètre inférieur à 10 µm
+ *pm25_kg* : particules en suspension dans l’air de diamètre inférieur à 2.5 µm
+ *co_kg* : monoxyde de carbone
+ *c6h6_kg* : benzène
+ *nh3_kg* : ammoniac
+ *ges_teqco2* : gaz à effet de serre
+ *ch4_t* : méthane
+ *co2_t* : dioxyde de carbone
+ *n2o_t* : protoxyde d’azote
+ *latit* : sa latitude
+ *longit* : sa longitude

Dans la suite de ce rapport, nous utilisons la notation $\Delta$ pour faire référence à des plots qui sont disponibles dans le Rmd mais que nous avons décidé de ne pas inclure dans le rapport. 

```{r, echo=FALSE}
Data = read.csv("Data-projetmodIA-2324.csv", header = TRUE)
```

```{r, echo=FALSE}
head(Data)
```

```{r, echo = FALSE}
Data$TypeEPCI=as.factor(Data$TypeEPCI)
Data$annee_inv=as.factor(Data$annee_inv)
Data$nomdepart=as.factor(Data$nomdepart)
Data$lib_epci=as.factor(Data$lib_epci)
Data$Ardèche = as.factor(Data$Ardèche)
Data$Ariège = as.factor(Data$Ariège)
Data$Aude = as.factor(Data$Aude)
Data$Aveyron = as.factor(Data$Aveyron)
Data$Gard = as.factor(Data$Gard)
Data$Haute.Garonne = as.factor(Data$Haute.Garonne)
Data$Gers = as.factor(Data$Gers)
Data$Hérault = as.factor(Data$Hérault)
Data$Landes = as.factor(Data$Landes)
Data$Lot = as.factor(Data$Lot)
Data$Lot.et.Garonne = as.factor(Data$Lot.et.Garonne)
Data$Lozère = as.factor(Data$Lozère)
Data$Pyrénées.Atlantiques = as.factor(Data$Pyrénées.Atlantiques)
Data$Hautes.Pyrénées = as.factor(Data$Hautes.Pyrénées)
Data$Pyrénées.Orientales = as.factor(Data$Pyrénées.Orientales)
Data$Tarn = as.factor(Data$Tarn)
Data$Tarn.et.Garonne = as.factor(Data$Tarn.et.Garonne)
Data$Vaucluse = as.factor(Data$Vaucluse)
```

```{r, echo = FALSE, include = FALSE}
summary(Data)
```
```{r str, include = FALSE}
str(Data)
```

## Analyse unidimentionnelle

### Analyse des variables quantitatives

Nous observons avec ce boxplot que nos variables n'ont pas les mêmes ordres de grandeur, cela va biaiser nos analyses de variances. Nous appliquons donc une transformation logarithmique aux valeurs quantitatives.

```{r, echo = FALSE}
Datalog = Data
Datalog[,4:14] = log(Datalog[,4:14])
```

```{r, echo = FALSE}
t = ggplot(melt(Data[,4:14]),aes(x=variable,y=value))+geom_boxplot()
p = ggplot(melt(Datalog[,4:14]),aes(x=variable,y=value))+geom_boxplot()
grid.arrange(t, p, ncol=2)
```
Nous remarquons que la transformation logarithme suffit à mieux visualiser nos données. Nous conserverons ce jeu de données transformé par la suite.
Nous stockons le dataset avec les variables quantitatives transformées dans la variable $Datalog$.

Nous affichons maintenant la fonction de répartition de la concentration d'oxyde d'azote. 

$(\Delta)$ D'autres graphes similaires sont disponibles dans le Rmd. 

à enlever surement 
```{r, echo = FALSE}
ggplot(Datalog) +
  aes(x = nox_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde d'azote en kg")
```

Les données sont uniformément réparties. Nous utiliserons donc ce dataset pour la suite de notre étude.

 boucle for to do 
```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = so2_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde de soufre en kg")
```

```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = co_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration de monoxyde de carbone")
```
```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = pm25_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde d'azote en kg")
```
```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = pm25_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde d'azote en kg")
```
```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = pm25_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde d'azote en kg")
```

### Analyse des variables qualitatives

Nous nous intéressons maintenant aux variables qualitatives : $TypeEPCI$ & $annee_inv$.
$(\Delta)$ Nous remarquons que nous avons le même nombre de prises de mesure pour chaque année, donc aucunes données ne semblent manquer.

```{r, echo = FALSE, include = FALSE}
ggplot(Data) + aes(annee_inv) + geom_bar()+ ggtitle("Répartition du nombre de mesure en fonction des années")
```

Nous affichons la répartition des mesures en fonction de $TypeEPCI$. Nous remarquons que les catégories CA, CU et Metropole ne comprennent pas beaucoup de valeurs par rapport au type CC. Nous choissisons donc de combiner les trois catégories pour avoir un nombre suffisant de valeurs pour chacunes de nos modalités.

changer titre
```{r,  echo = FALSE}
Datalog_ = Datalog
levels(Datalog_[c(3,10,12, 14,15)]$TypeEPCI) <- c("CA/CU/Métropole", "CC", "CA/CU/Métropole", "CA/CU/Métropole")
```
```{r, echo = FALSE}
t = ggplot(Data) + aes(TypeEPCI) + geom_bar()+ ggtitle("Répartition du nombre de mesure en fonction du Type EPCI (avant)")
p = ggplot(Datalog_) + aes(TypeEPCI) + geom_bar()+ ggtitle("Répartition du nombre de mesure en fonction du Type EPCI (après)")
grid.arrange(t, p, ncol=2)
```

## Analyse bidementionnelle

En affichant la matrice de corrélation des variables de notre dataset, nous observons que la plupart des polluants sont corrélés positivement les uns avec les autres à l'exception de $nh3\_kg$, $ch4\_t$ et $n2o\_t$ qui ne semblent être corrélés à aucune autre variable.

```{r}
corrplot(cor(Datalog_[4:14]), method="ellipse")
```

Nous constatons avec le boxplot ci-dessous qu'il y a un lien entre le type EPCI et les différents polluants. En effet les boxplot en fonction des types sont à des niveaux différents. Rajouter titre ?
```{r}
ggplot(Datalog_, aes(x = TypeEPCI, y = pm10_kg)) + geom_boxplot()
```


# Visualisation des individus

Nous réalisons une ACP pour visualiser nos données dans un espace de dimension inférieure.

```{r,  echo = FALSE}
ACPpolluants <- PCA(Datalog_[,1:16], scale.unit = TRUE, ncp = 11, quali.sup = c(1,2,3,15,16), graph = FALSE)
```

Nous remarquons avec les graphes ci-dessous que les deux premières dimensions constituent 90% de la variance. Nous allons poursuivre les analyses par ces deux dimensions.

```{r,  echo = FALSE}
ggplot(data.frame(ACPpolluants$eig)) + aes(x = 1:11, y =ACPpolluants$eig[,"percentage of variance"]) + geom_col() + xlab("Dimension") + ylab("%") + ggtitle("Pourcentage de variance par dimension")
ggplot(data.frame(ACPpolluants$eig)) + aes(x = 1:11, y =ACPpolluants$eig[,"cumulative percentage of variance"]) + geom_col() + xlab("Dimension") + ylab("%") + ggtitle("Pourcentage de variance cumulée") + geom_hline(yintercept=90, linetype="dashed", color = "red")
```

Nous affichons le cercle des corrélations. La première dimension décrit toutes les variables sauf $ch4\_t$, $nh3\_kg$ et $n2o\_t$ qui décrivent la deuxième dimension.

```{r,  echo = FALSE}
fviz_pca_var(ACPpolluants,axes =c(1,2))
```
Nous remarquons que les 3 polluants qui ne sont pas corrélés avec les autres polluants (cf corrplot) composent la deuxième dimension de l'ACP.


Nous affichons également le graphe des individus colorés en fonction du Type EPCI. Nous remarquons que les types CA/CU/Metropole ont tendance à avoir en plus grandes quantité les polluants de la première dimension.
Nous remarquons aussi deux groupements extrêmes. Un groupement très peu pollué et un autre plus pollué. Après identification, il s'agit de Toulouse Métropole et de CC Pays de Nay. Nous décidons d'enlever ces deux groupements car ils ne représentent pas la tendance général ; ce sont des outliers qui créeront une grande disparité.

```{r,  echo = FALSE}
fviz_pca_ind(ACPpolluants,col.ind=as.factor(Datalog_$TypeEPCI),geom = c("point"),axes=c(1,2))
```

Remarque : Nous constatons, avec le graphique ci dessous, que chaque regroupement corresponds à une ville grâce à l'habillage par année. Cette visualisation nous a permis d'éliminer les outliers.

```{r,  echo = FALSE}
fviz_pca_ind(ACPpolluants,col.ind=as.factor(Datalog$annee_inv),geom = c("point"),axes=c(1,2)) #utile de mettre celui avec les années ?
```

$(\Delta)$ Nous affichons aussi cette représentation sans le groupement des $TypeEPCI$. Cela confirme que nous avons un classement de la pollution en fonction du Type EPCI. Si nous alons du plus au moins pollué, nous avons : Metropole, CU, CA puis CC.

```{r,  echo = FALSE, include = FALSE}
fviz_pca_ind(ACPpolluants,col.ind=as.factor(Datalog$TypeEPCI),geom = c("point"),axes=c(1,2))
```

```{r,  echo = FALSE}
Data_final <- subset(Datalog_, lib_epci != "Toulouse Métropole")
Data_final <- subset(Data_final, lib_epci != "CC Pays de Nay")
```

$\Delta$ Nous réaffichons les mêmes graphes sans les deux outliers.

```{r,  echo = FALSE, include = FALSE}
ACPpolluants_ <- PCA(Data_final[1:16], scale.unit = TRUE, ncp = 3, quali.sup = c(1,2,3,15,16), graph = FALSE)
fviz_pca_var(ACPpolluants_,axes =c(1,2))
fviz_pca_ind(ACPpolluants_,col.ind=as.factor(Data_final$TypeEPCI),geom = c("point"),axes=c(1,2))
```

# Clustering (pas rédigé)
<!-- TODO : changer le titre peut-être (genre "Classification des ...") -->
<!-- TODO : rédiger la partie clustering -->
<!-- TODO : repasser sur les codes, notamment les parties indiquées "# A completer" --> 

```{r}
reskmeans<-kmeans((Data_final[,4:14]),centers=5)
table(reskmeans$cluster)
fviz_cluster(reskmeans,data=Data_final[,4:14],ellipse.type="norm",labelsize=8,geom=c("point"), axes = c(1,2))+ggtitle("")
```

```{r}
reskmeans<-kmeans((Datalog[,4:14]),centers=7)
table(reskmeans$cluster)
fviz_cluster(reskmeans,data=Datalog[,4:14],ellipse.type="norm",labelsize=8,geom=c("point"), axes = c(1,2))+ggtitle("")
```
```{r,eval=F}
# A completer
Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(Data_final),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(Data_final[,4:14],centers=k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:15,Iintra=Iintra)
ggplot(df,aes(x=K,y=Iintra))+geom_line()+geom_point()+xlab("Nombre de classes")+ylab("Inertie intraclasse")
```
```{r,eval=F}
# A completer
Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(Datalog),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(Datalog[,4:14],centers=k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:15,Iintra=Iintra)
ggplot(df,aes(x=K,y=Iintra))+geom_line()+geom_point()+xlab("Nombre de classes")+ylab("Inertie intraclasse")
```

<!-- MODIF : AJOUT DE LA PARTIE CAH DE CUSTERING  -->
```{r,eval=F}
Data_CAH = Data_final[,4:14]
```

```{r,eval=F}
# A completer : FAIT
CH<-NULL
Kmax<-20
for (k in 2:Kmax){
  CH<-c(CH,index.G1(Data_CAH,cutree(hc,k)))
}
daux<-data.frame(NbClust=2:Kmax,CH=CH)
ggplot(daux,aes(x=NbClust,y=CH))+geom_line()+geom_point()
```
```{r,eval=F}
ClustCH<-cutree(hc,which.max(CH)+1)
fviz_dend(hc,show_labels = FALSE,k=which.max(CH)+1)
```
```{r,eval=F}
fviz_cluster(hc,Data_CAH,ellipse.type="norm",labelsize=8,geom=c("point"),axes=c(1,2)) + ggtitle("")
table(hc$order)
```


```{r,eval=F}
d=dist(Data_CAH, method = "euclidean")
hc=hclust(d,method="single")
#ggdendogram(hc)
classK5 <- cutree(hc, k = 5)
fviz_dend(hc, k=5, show_labels=FALSE)
```

```{r,eval=F}
Data_CAH = Data_final[,4:14]
d=dist(Data_CAH, method = "euclidean")
hc=hclust(d,method="complete")
#ggdendogram(hc)
fviz_dend(hc, k = 5, show_labels=FALSE)
```

```{r,eval=F}
Data_CAH = Data_final[,4:14]
d=dist(Data_CAH, method = "euclidean")
hc=hclust(d,method="average")
#ggdendogram(hc)
fviz_dend(hc,show_labels=FALSE)
```

```{r,eval=F}
Data_CAH = Data_final[,4:14]
d=dist(Data_CAH, method = "euclidean")
hc=hclust(d,method="ward")
#ggdendogram(hc)
fviz_dend(hc,show_labels=FALSE)
```


# Etude de l'émission de méthane (ANCOVA)

Nous souhaitons étudier l'émission de méthane $ch4\_t$ en fonction de l'ammoniac $nh3\_kg$, du protoxyde d'azote $n2o\_t$, du type d'EPCI $TypeEPCI$ et de l'année $annee\_inv$. Nous avons des variables quantitatives et qualitatives, nous allons donc faire une ANCOVA. Nous effectuons l'ANCOVA sur les données modifiées (par le logarithme).

Dans un premier temps, on considère le modèle complet avec interactions.

$$
(M_1) 
\left\{\begin{array}{l} ch4\_t_{ijk}= \mu + \alpha_i + \beta_j + \gamma_{ij} + (a1 + a2_i + a3_j)\times nh3\_kg_{ijk} + (b1 + b2_i + b3_j)\times n2o\_t_{ijk} + \nu \times n2o\_t_{ijk} \times nh3\_kg_{ijk} +
\varepsilon_{ijk},\ \\
i=1,\ldots,I=6,\ j=1 \ldots,J=2, \ k=1,\ldots,n_{ij}.\\ (\varepsilon_{ijk})_{i,j,k} \textrm{ i.i.d
} \ \mathcal{N}(0,\sigma^2) \end{array}\right. 
$$

$ch4\_t_{ijk}$ représentes la valeur de la $k^{ème}$ mesure du $ch4\_t$ pour la $i^{ème}$ année et pour le $j^{ème}$ type d'EPCI.

```{r,  echo = TRUE }
complet<-lm(ch4_t ~ .^2 ,data=Datalog_[c(3,10,12, 14,15)])
summary(complet)
```

Au vue des sorties des tests de student pour chaque coefficient, il semblerait que nous puissions supprimer certaines de ces interactions. Nous allons donc essayer de réduire notre modèle. Pour cela, nous supposons d'abord le modèle suivant sans interactions : 

$$
(M_2) 
\left\{\begin{array}{l} ch4\_t_{ijk}= \mu + \alpha_i + \beta_j + \theta \times nh3\_kg_{ijk} + \gamma \times n2o\_t_{ijk} + 
\varepsilon_{ijk},\ \\
i=1,\ldots,I=6,\ j=1 \ldots,J=2, \ k=1,\ldots,n_{ij}.\\ (\varepsilon_{ijk})_{i,j,k} \textrm{ i.i.d
}\mathcal{N}(0,\sigma^2) \end{array}\right. 
$$

```{r,  echo = FALSE,  include = FALSE}
mod_si<-lm(ch4_t ~ . ,data=Datalog_[c(3,10,12, 14,15)])
summary(mod_si)
```

Nous effectuons alors un test de sous modèle de Fisher pour voir si nous pouvons enlever les interactions.

```{r, echo=FALSE}
anova(mod_si,complet)
```

Notre p-valeur est très faible, nous ne pouvons pas supprimer toutes les interactions. Nous allons à la place utiliser un algorithme de sélection de variable pour réduire notre modèle.

Nous choissisons la méthode backward avec les critères BIC et AIC.

```{r, echo = FALSE}
stepAIC(complet,trace=F,direction="backward")
```

```{r, echo = FALSE}
stepAIC(complet,trace=F,direction="backward",k=log(nrow(Datalog_[c(3,10,12, 14,15)])))
```

Les deux algorithmes nous donne le même sous modèle :

$$
(M_3) 
\left\{\begin{array}{l} ch4\_t_{ijk}= \mu + \alpha_i + \beta_j + (a1 + a3_j)\times nh3\_kg_{ijk} + (b1 + b3_j)\times n2o\_t_{ijk} + \nu \times n2o\_t_{ijk} \times nh3\_kg_{ijk} +
\varepsilon_{ijk},\ \\
i=1,\ldots,I=6,\ j=1 \ldots,J=2, \ k=1,\ldots,n_{ij}.\\ (\varepsilon_{ijk})_{i,j,k} \textrm{ i.i.d
} \ \mathcal{N}(0,\sigma^2) \end{array}\right. 
$$

Nous avons supprimé 3 coefficients. Nous vérifions ce resultat avec un test de sous modèle.

```{r}
M3 = lm(ch4_t ~ annee_inv + nh3_kg + n2o_t + TypeEPCI + 
    nh3_kg:n2o_t + nh3_kg:TypeEPCI + n2o_t:TypeEPCI, data = Datalog_[c(3, 
    10, 12, 14, 15)])
```

```{r, echo = FALSE}
anova(M3, complet)
```

Notre p-valeur est bien supérieur à $0.05$ donc on ne rejette pas ce sous modèle.

Par curiosité, nous avons voulu supprimer certaines interactions manuellement. Nous avons trouvé que nous pouvions supprimer l'interaction entre $nh3\_kg$ et $n2o\_t$ et toujours avoir une p-valeur supérieure à $0.05$.

```{r, echo = FALSE}
anova(lm(formula = ch4_t ~ annee_inv + nh3_kg + n2o_t + TypeEPCI + 
     nh3_kg:TypeEPCI + n2o_t:TypeEPCI, data = Datalog_[c(3, 
    10, 12, 14, 15)]), complet)
```

Nous pourrions alors considérer le modèle final suivant : 

$$
(M_4) 
\left\{\begin{array}{l} ch4\_t_{ijk}= \mu + \alpha_i + \beta_j + (a1 + a3_j)\times nh3\_kg_{ijk} + (b1 + b3_j)\times n2o\_t_{ijk} +
\varepsilon_{ijk},\ \\
i=1,\ldots,I=6,\ j=1 \ldots,J=2, \ k=1,\ldots,n_{ij}.\\ (\varepsilon_{ijk})_{i,j,k} \textrm{ i.i.d
} \ \mathcal{N}(0,\sigma^2) \end{array}\right. 
$$


## Dépassement d'émission de méthane (Modèle linéaire généralisé)

Dans cette section, nous allons expliquer le dépassement d'émission de méthane ($ch4$)de $1000t$ par an en fonction de l'ammoniac ($nh3$), du protoxyde d'azote ($n2o$), du type d'EPCI et de l'année par un modèle linéaire généralisé.

Nous créons la nouvelle variable booléenne $Data\_mlg$, valant 1 si le taux de méthane $ch4\_t$ est supérieur à $1000t$, 0 sinon.

```{r, echo=FALSE, eval=TRUE}
# REDÉ
Data = read.csv("Data-projetmodIA-2324.csv", header = TRUE)
Data$TypeEPCI=as.factor(Data$TypeEPCI)
Data$annee_inv=as.factor(Data$annee_inv)
Data$nomdepart=as.factor(Data$nomdepart)
Data$lib_epci=as.factor(Data$lib_epci)
Data$Ardèche = as.factor(Data$Ardèche)
Data$Ariège = as.factor(Data$Ariège)
Data$Aude = as.factor(Data$Aude)
Data$Aveyron = as.factor(Data$Aveyron)
Data$Gard = as.factor(Data$Gard)
Data$Haute.Garonne = as.factor(Data$Haute.Garonne)
Data$Gers = as.factor(Data$Gers)
Data$Hérault = as.factor(Data$Hérault)
Data$Landes = as.factor(Data$Landes)
Data$Lot = as.factor(Data$Lot)
Data$Lot.et.Garonne = as.factor(Data$Lot.et.Garonne)
Data$Lozère = as.factor(Data$Lozère)
Data$Pyrénées.Atlantiques = as.factor(Data$Pyrénées.Atlantiques)
Data$Hautes.Pyrénées = as.factor(Data$Hautes.Pyrénées)
Data$Pyrénées.Orientales = as.factor(Data$Pyrénées.Orientales)
Data$Tarn = as.factor(Data$Tarn)
Data$Tarn.et.Garonne = as.factor(Data$Tarn.et.Garonne)
Data$Vaucluse = as.factor(Data$Vaucluse)
Datalog = Data
Datalog[,4:14] = log(Datalog[,4:14])
Datalog_ = Datalog
levels(Datalog_[c(3,10,12, 14,15)]$TypeEPCI) <- c("CA/CU/Métropole", "CC", "CA/CU/Métropole", "CA/CU/Métropole")
Data_final <- subset(Datalog_, lib_epci != "Toulouse Métropole")
Data_final <- subset(Data_final, lib_epci != "CC Pays de Nay")


Data_mlg = Data_final[c(3,10,12,14,15)]
# Création d'une nouvelle variable qualitative (celle qui traduit méthane > 1000t)
Data_mlg$dep_met_1000 <- as.logical(Data_mlg$ch4_t>log(1000))
# Retrait de la variable quantitative ch4_t
Data_mlg <- Data_mlg[c(1,2,4,5,6)]
#Data_mlg[,2:3] = scale(Data_mlg[,2:3])
head(Data_mlg)
```

La variable $dep\_met\_1000$ étant binaire, nous allons utiliser la régression logistique.

Dans un premier temps, nous créons le modèle complet avec interactions, modèle que l'on note $(\mathcal{M}_{GL_{1}})$ :

$$
\begin{equation*}
(\text{M}_{GL_{1}}) : 
\begin{cases}
\begin{aligned}
\text{dep_met_1000}_i \sim & ~ \mathcal{B}(\pi(x_i)) \text{, dep_met_1000}_1 \text{, ..., dep_met_1000}_n \text{ indépendant.}& \\ 
\\
\text{logit}[\pi(x_i)] = \ln(\cfrac{\pi(x_i)}{1 - \pi(x_i)})  = & ~ \mu  +  \theta_1\cdot\text{nh3_kg}_i  + \theta_2\cdot\text{n2o_t}_i  +  \gamma\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i  \\ 
& + (\beta_1  +  \beta_2\cdot\text{nh3_kg}_i ~ + \beta_3\cdot\text{n2o_t}_i )\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}} \\
&  + \sum_{k=1}^5 (\delta_{1k}  +  \delta_{2k}\cdot\text{nh3_kg}_i ~ + \delta_{3k}\cdot\text{n2o_t}_i )\mathbb{1}_{\text{annee}_i = 2014 + k} \\
& + \sum_{k=1}^5 (\kappa_{1k} \cdot \mathbb{1}_{\text{TypeEPCI}_i = \text{CC}}\cdot\mathbb{1}_{\text{annee}_i = 2014 + k}) \\
\end{aligned}
\end{cases}
\end{equation*}
$$

```{r, echo=FALSE, eval=TRUE, warning=FALSE}
mlg_complet = glm(dep_met_1000~(.)^2, data=Data_mlg, family=binomial(link = "logit"))
```

Nous observons que certaines variables du modèle complet ont une p-valeur > 0.05. Nous allons nous intéresser à la simplification du modèle.
Nous commencons par faire un test de sous-modèle entre le modèle complet et le modèle sans interactions.

<!-- TODO : écrire le test de sous-modèle que l'on s'apprète à faire (avec H_0 et H_1), éventuellement évoquer le fait que c'est un test de Wald (si pertinent et avéré)  --> 
```{r, echo=FALSE, eval=FALSE, warning=FALSE}
mlg_si = glm(dep_met_1000~., data=Data_mlg, family=binomial(link = "logit"))
```

```{r, echo=FALSE, eval=FALSE}
anova(mlg_complet, mlg_si, test="Chisq")
```
Nous obtenons une p-valeur << 0.05. On rejette donc l'hypothèse $\mathcal{H_0}$, et nous devons conserver dans un premier temps le modèle complet, avec toutes les interactions.
Nous allons maintenant appliquer des algorithmes de selection de variables pour réduire le modèle complet.

<!-- TODO : Dans tous les algorithmes faut qu'on fasse gaffe, ils ne semblent ne prendre que les variables d'interaction (et plus les variables additives). La prof avait dit qu'il fallait faire gaffe à ça je crois, j'avais entendu d'une oreille la dernière fois --> 
<!-- MODIF : ajout de "warning = F" -->
```{r, warning = F}
step.backward <- step(mlg_complet)
```
```{r, echo = FALSE, eval = TRUE}
stepAIC(mlg_complet, direction=c("backward"),p=2,trace=0) # AIC
```
```{r, echo = FALSE, eval = TRUE}
stepAIC(mlg_complet, direction=c("backward"),p=log(nrow(Data_mlg))) # BIC
```

Nous utilisons 3 méthodes d'algorithme de selection de variable en méthode backward et les 3 s'accordent sur le même modèle.

$$
\begin{equation*}
(\text{M}_{GL_{2}}) : 
\begin{cases}
\begin{aligned}
\text{dep_met_1000}_i \sim & ~ \mathcal{B}(\pi(x_i)) \text{, dep_met_1000}_1 \text{, ..., dep_met_1000}_n \text{ indépendant.}& \\ 
\\
\text{logit}[\pi(x_i)] = \ln(\cfrac{\pi(x_i)}{1 - \pi(x_i)})  = & ~ \mu  +  \theta_1\cdot\text{nh3_kg}_i  + \theta_2\cdot\text{n2o_t}_i  +  \gamma\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i  \\ 
& + (\beta_1  +  \beta_2\cdot\text{nh3_kg}_i ~ + \beta_3\cdot\text{n2o_t}_i )\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}} \\
\end{aligned}
\end{cases}
\end{equation*}
$$

```{r, echo = FALSE, eval = TRUE}
mlg_reduit = glm(formula = dep_met_1000 ~ annee_inv + nh3_kg + n2o_t + TypeEPCI + 
    nh3_kg:n2o_t + nh3_kg:TypeEPCI + n2o_t:TypeEPCI, family = binomial(link = "logit"), 
    data = Data_mlg)
```
Nous effectuons un test de sous-modèle pour le valider. La p-valeur est de 0.5528 > 0.05. Nous ne rejetons alors pas le modèle réduit.
<!-- TODO : au passage le "Chisq" doit pouvoir se justifier avec le fait qu'on fait un test de Wald ou un truc dans le genre -->
```{r, echo = FALSE, eval = TRUE}
anova(mlg_reduit, mlg_complet, test = "Chisq")
```
On a : $T := \mathcal{D}(M_0) - \mathcal{D}(M_1) \sim \chi^2(k_1 - k_0)$, avec $\mathcal{D}(M) = -2\{l(Y,\hat{\theta}) - l(Y,\hat{\theta}_{sat})\}$.
Avec les sorties R, on constate : $T^{obs} = 13,643,$ puis pvaleur = $\mathbb{P}(T > T^{obs}) = 0.55$.

On a pvaleur $> 0.05$, on conserve donc le modèle réduit au risque $5\%$.

<!-- TODO : écrire la formule du pseudo R2, compléter son interprétation -->
```{r, echo=FALSE, eval=T}
pseudoR2 = 1 - mlg_reduit$deviance/mlg_reduit$null.deviance
pseudoR2
```

Le $\text{pseudoR}^2$ du modèle réduit vaut 0.6490327, c'est une valeur satisfaisante pour fitter notre modèle.

