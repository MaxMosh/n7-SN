---
title: "Projet d'étude : Analyse de données & Éléments de modélisation statistique"
output:
  pdf_document: default
  html_document: default
date: "2023-09-29"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r,echo=F, error=F,warning=F}
library(corrplot)
#library(tidyverse)
library(gridExtra)
library(reshape2)
library(ggplot2)
library(FactoMineR)
```

# Statistiques descriptives

Le jeu de données comprend $984$ mesures des émissions de polluants atmosphériques tous secteurs d’activités confondues des EPCI (Etablissements Publics de Coopération Intercommunale) de la région Occitanie de 2014 à 2019.

Chaque mesure est décrite par les variables qualitatives suivantes :
+ *lib_epci* : son nom
+ *code_epci* : son code d’identification
+ *nomdepart* : son (ses) département(s) d’appartenance
+ *TypeEPCI* : CC (communauté de commune), CA (communauté d’agglomération), Métrople et CU (communauté urbaine)
+ *annee_inv* : l'année de mesure

Et par les variables quantitatives suivantes : 
+ *nox_kg* : oxyde d’azote en kg
+ *so2_kg* : oxyde de soufre en kg
+ *pm10_kg* : particules en suspension dans l’air de diamètre inférieur à 10 µm
+ *pm25_kg* : particules en suspension dans l’air de diamètre inférieur à 2.5 µm
+ *co_kg* : monoxyde de carbone
+ *c6h6_kg* : benzène
+ *nh3_kg* : ammoniac
+ *ges_teqco2* : gaz à effet de serre
+ *ch4_t* : méthane
+ *co2_t* : dioxyde de carbone
+ *n2o_t* : protoxyde d’azote
+ *latit* : sa latitude
+ *longit* : sa longitude

Dans la suite de ce rapport, nous utilisons la notation $\Delta$ pour faire référence à des plots qui sont disponibles dans le Rmd mais que nous avons décidé de ne pas inclure dans le rapport. 

```{r, echo=FALSE}
Data = read.csv("Data-projetmodIA-2324.csv", header = TRUE)
```

```{r, echo=FALSE}
head(Data)
```

```{r, echo = FALSE}
Data$TypeEPCI=as.factor(Data$TypeEPCI)
Data$annee_inv=as.factor(Data$annee_inv)
Data$nomdepart=as.factor(Data$nomdepart)
Data$lib_epci=as.factor(Data$lib_epci)
Data$Ardèche = as.factor(Data$Ardèche)
Data$Ariège = as.factor(Data$Ariège)
Data$Aude = as.factor(Data$Aude)
Data$Aveyron = as.factor(Data$Aveyron)
Data$Gard = as.factor(Data$Gard)
Data$Haute.Garonne = as.factor(Data$Haute.Garonne)
Data$Gers = as.factor(Data$Gers)
Data$Hérault = as.factor(Data$Hérault)
Data$Landes = as.factor(Data$Landes)
Data$Lot = as.factor(Data$Lot)
Data$Lot.et.Garonne = as.factor(Data$Lot.et.Garonne)
Data$Lozère = as.factor(Data$Lozère)
Data$Pyrénées.Atlantiques = as.factor(Data$Pyrénées.Atlantiques)
Data$Hautes.Pyrénées = as.factor(Data$Hautes.Pyrénées)
Data$Pyrénées.Orientales = as.factor(Data$Pyrénées.Orientales)
Data$Tarn = as.factor(Data$Tarn)
Data$Tarn.et.Garonne = as.factor(Data$Tarn.et.Garonne)
Data$Vaucluse = as.factor(Data$Vaucluse)
```

```{r, echo = FALSE, include = FALSE}
summary(Data)
```
```{r str, include = FALSE}
str(Data)
```

## Analyse unidimentionnelle

### Analyse des variables quantitatives

Nous observons avec ce boxplot que nos variables n'ont pas les mêmes échelles de valeur (MODIF : ordres de grandeur), cela va biaiser nos analyses de variances. Nous appliquons donc une transformation logarithmique aux valeurs quantitatives.

```{r, echo = FALSE}
ggplot(melt(Data[4:14]),aes(x=variable,y=value))+geom_boxplot()
```

<!-- TODO : mettre graphe cote à cote --> 
Nous stockons le dataset avec les variables quantitatives transformées dans la variable $Datalog$. <!-- MODIF : j'ai changé un peu la phrase --> 

```{r, echo = FALSE}
Datalog = Data
Datalog[,4:14] = log(Datalog[,4:14])
```

Nous remarquons que la transformation logarithme suffit à mieux visualiser nos données. Nous utiliserons ce jeu de données par la suite.

```{r, echo = FALSE}
ggplot(melt(Datalog[,4:14]),aes(x=variable,y=value))+geom_boxplot()
```

<!-- MODIF (à faire) : est-ce qu'on supprime le bout de code R qui suit ? --> 
```{r, echo = FALSE}
#ggplot(Datalog) + # plot fonction densité
 # aes(x = nox_kg) +
#  geom_density() +
 # ggtitle("Nombre") +
  #xlab("Heures") +
  #ylab("Densité")
```

Nous affichons maintenant la fonction de répartition de la concentration d'oxyde d'azote. 

$(\Delta)$ D'autres graphes similaires sont disponibles dans le Rmd. <!-- MODIF : j'ai modifié un peu l'approche avec le delta --> 

```{r, echo = FALSE}
ggplot(Datalog) +
  aes(x = nox_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde d'azote en kg")
```

Les données sont uniformément réparties. Cela confirme que nous n'avons pas besoin d'appliquer d'autres transformations aux variables quantitatives.
<!-- MODIF (proposition) : peut-être qu'on peut changer la deuxième phrase en :
"Nous utiliserons donc ce dataset pour la suite de notre étude."
Peut-être qu'on pourrait nous reprocher que de manière générale, ça ne suffit pas à confirmer qu'on a rien besoin d'appliquer d'autres aux données. --> 

```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = so2_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde de soufre en kg")
```

```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = co_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration de monoxyde de carbone")
```
```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = pm25_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde d'azote en kg")
```
```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = pm25_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde d'azote en kg")
```
```{r, echo = FALSE, include = FALSE}
ggplot(Datalog) +
  aes(x = pm25_kg) +
  stat_ecdf() +
  ylab(" ") +
  ggtitle("Fonction de répartition de la concentration d'oxyde d'azote en kg")
```

### Analyse des variables qualitatives

Nous nous intéressons maintenant aux variables qualitatives : $TypeEPCI$ & $annee_inv$.
$(\Delta)$ Nous remarquons que nous avons le même nombre de prises de mesure pour chaque année, donc aucunes données ne semblent manquer.

```{r, echo = FALSE, include = FALSE}
ggplot(Data) + aes(annee_inv) + geom_bar()+ ggtitle("Répartition du nombre de mesure en fonction des années")
```

Nous affichons la répartition des mesures en fonction de $TypeEPCI$. Nous remarquons que les catégories CA, CU et Metropole ne comprennent pas beaucoup de valeurs par rapport au type CC. Nous choissisons donc de combiner les trois catégories pour avoir un nombre suffisant de valeurs pour chacun de nos différents niveaux.

```{r, echo = FALSE}
ggplot(Data) + aes(TypeEPCI) + geom_bar()+ ggtitle("Répartition du nombre de mesure en fonction du Type EPCI (avant)")
```

<!-- TODO : mettre graphe cote à cote --> 

```{r,  echo = FALSE}
Datalog_ = Datalog
levels(Datalog_[c(3,10,12, 14,15)]$TypeEPCI) <- c("CA/CU/Métropole", "CC", "CA/CU/Métropole", "CA/CU/Métropole")
ggplot(Datalog_) + aes(TypeEPCI) + geom_bar()+ ggtitle("Répartition du nombre de mesure en fonction du Type EPCI (après)")
```


## Analyse bidementionnelle

En affichant le corrplot, nous observons que tout les polluants sont corrélés positivement les uns aux autres sauf nh3_kg, ch4_t et n2o_t. En effet, ces derniers semblents être corrélés seulement qu'entre eux.

<!-- MODIF (proposition) : je modifierais les deux phrases du dessus de la manière suivante :
"En affichant la matrice de corrélation des variables de notre Dataset, nous observons que la plupart des polluants sont corrélés positivement les uns avec les autres à l'exception de nh3_kg, ch4_t et n2o_t qui ne semblent être corrélés à aucune autre variable."
--> 

```{r}
corrplot(cor(Datalog_[4:14]), method="ellipse")
```

<!-- TODO : subplot --> 

```{r}
boxplot(Datalog$pm10_kg~Datalog$TypeEPCI)
```


# ACP
<!-- TODO : faut qu'on modifie ce titre, je te propose "Visualisation des individus" (comme dans le sujet un peu lol) --> 

```{r}
library(mclust)
library(cluster)
library(factoextra)
library(FactoMineR)
library(ppclust)
library(reticulate)
library(ggplot2)
library(reshape)
library(corrplot)
library(gridExtra)
library(circlize)
library(viridis)
library(reshape2)
library(klaR)
```

Nous réalisons une ACP pour visualiser nos données dans un espace de dimension inférieure.

```{r,  echo = FALSE}
ACPpolluants <- PCA(Datalog_[,1:16], scale.unit = TRUE, ncp = 11, quali.sup = c(1,2,3,15,16), graph = FALSE)
```

Nous remarquons avec les graphes ci-dessous que les deux premières dimensions constituent 90% de la variance. Nous allons poursuivre les analyses par ces deux dimensions.

```{r,  echo = FALSE}
ggplot(data.frame(ACPpolluants$eig)) + aes(x = 1:11, y =ACPpolluants$eig[,"percentage of variance"]) + geom_col() + xlab("Dimension") + ylab("%") + ggtitle("Pourcentage de variance par dimension")
ggplot(data.frame(ACPpolluants$eig)) + aes(x = 1:11, y =ACPpolluants$eig[,"cumulative percentage of variance"]) + geom_col() + xlab("Dimension") + ylab("%") + ggtitle("Pourcentage de variance cumulée")
```

<!-- TODO : mettre droite -->

Nous affichons le cercle des corrélations. La première dimension est consituée de la majorité des polluants sauf ch4_t, nh3_kg et n2o_t qui constituent la deuxième dimension. 

<!-- MODIF (proposition) : je te propose (c'est le verbe constituer qui me gêne un peu)
"La première dimension décrit toutes les variables sauf ch4_t, nh3_kg et n2o_t qui décrivent la deuxième dimension."
--> 

<!-- TODO : mettre lien avec l'autre corrplot -->

```{r,  echo = FALSE}
fviz_pca_var(ACPpolluants,axes =c(1,2))
```

Nous affichons également le graphe des individus colorés en fonction du Type EPCI. Nous remarquons que les types CA/CU/Metropole ont tendance à avoir en plus grandes quantité les polluants de la première dimension.   <!-- MODIF : j'ai modifié un peu la tournure de la phrase --> 
Nous remarquons aussi deux groupements extrêmes. Un groupement très peu pollué et un autre plus pollué. Après identification, il s'agit de Toulouse Métropole et de CC Pays de Nay. Nous décidons d'enlever ces deux groupements car ils ne représentent pas la tendance général ; ce sont des outliers qui créeront une grande disparité.    <!-- MODIF : j'ai modifié un peu la tournure de la phrase --> 

```{r,  echo = FALSE}
fviz_pca_ind(ACPpolluants,col.ind=as.factor(Datalog_$TypeEPCI),geom = c("point"),axes=c(1,2))
#fviz_pca_ind(ACPpolluants,col.ind=as.factor(Datalog$annee_inv),geom = c("point"),axes=c(1,2)) utile de mettre celui avec les années ?
```

$(\Delta)$ Nous affichons aussi cette représentation sans le groupement des $TypeEPCI$. Cela confirme que nous avons un classement de la pollution en fonction du Type EPCI. Si on va du plus au moins pollué, on a : Metropole, CU, CA puis CC.

```{r,  echo = FALSE, include = FALSE}
fviz_pca_ind(ACPpolluants,col.ind=as.factor(Datalog$TypeEPCI),geom = c("point"),axes=c(1,2))
```

```{r,  echo = FALSE}
Data_final <- subset(Datalog_, lib_epci != "Toulouse Métropole")
Data_final <- subset(Data_final, lib_epci != "CC Pays de Nay")
```

$\Delta$ Nous réaffichons les mêmes graphes sans les deux outliers.

```{r,  echo = FALSE, include = FALSE}
ACPpolluants_ <- PCA(Data_final[1:16], scale.unit = TRUE, ncp = 3, quali.sup = c(1,2,3,15,16), graph = FALSE)  # Utilisation de scale.unit = TRUE pour    (TODO : faut qu'on supprime le commentaire ou qu'on le complète)
fviz_pca_var(ACPpolluants_,axes =c(1,2))
fviz_pca_ind(ACPpolluants_,col.ind=as.factor(Data_final$TypeEPCI),geom = c("point"),axes=c(1,2))
```

# Clustering (pas rédigé)
<!-- TODO : changer le titre peut-être (genre "Classification des ...") -->
<!-- TODO : rédiger la partie clustering -->
<!-- TODO : repasser sur les codes, notamment les parties indiquées "# A completer" --> 

```{r}
reskmeans<-kmeans((Data_final[,4:14]),centers=5)
table(reskmeans$cluster)
fviz_cluster(reskmeans,data=Data_final[,4:14],ellipse.type="norm",labelsize=8,geom=c("point"), axes = c(1,2))+ggtitle("")
```

```{r}
reskmeans<-kmeans((Datalog[,4:14]),centers=7)
table(reskmeans$cluster)
fviz_cluster(reskmeans,data=Datalog[,4:14],ellipse.type="norm",labelsize=8,geom=c("point"), axes = c(1,2))+ggtitle("")
```
```{r,eval=F}
# A completer
Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(Data_final),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(Data_final[,4:14],centers=k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:15,Iintra=Iintra)
ggplot(df,aes(x=K,y=Iintra))+geom_line()+geom_point()+xlab("Nombre de classes")+ylab("Inertie intraclasse")
```
```{r,eval=F}
# A completer
Kmax<-15
reskmeanscl<-matrix(0,nrow=nrow(Datalog),ncol=Kmax-1)
Iintra<-NULL
for (k in 2:Kmax){
  resaux<-kmeans(Datalog[,4:14],centers=k)
  reskmeanscl[,k-1]<-resaux$cluster
  Iintra<-c(Iintra,resaux$tot.withinss)
}

df<-data.frame(K=2:15,Iintra=Iintra)
ggplot(df,aes(x=K,y=Iintra))+geom_line()+geom_point()+xlab("Nombre de classes")+ylab("Inertie intraclasse")
```

# ANCOVA
<!-- TODO : mettre un titre un peu moins brutal aussi (quitte à même laisser ANCOVA entre parenthèses en suffixe) -->

Nous souhaitons étudier l'émission de méthane $ch4\_t$ en fonction de l'ammoniac $nh3\_kg$, du protoxyde d'azote $n2o\_t$, du type d'EPCI $TypeEPCI$ et de l'année $annee\_inv$. Nous avons des variables quantitatives et qualitatives, nous allons donc faire une ANCOVA. Nous effectuons l'ANCOVA sur les données modifiées (par le logarithme).

Dans un premier temps, on considère le modèle complet avec interactions.

$$
(M_1) 
\left\{\begin{array}{l} ch4\_t_{ijk}= \mu + \alpha_i + \beta_j + \gamma_{ij} + (a1 + a2_i + a3_j)\times nh3\_kg_{ijk} + (b1 + b2_i + b3_j)\times n2o\_t_{ijk} + \nu \times n2o\_t_{ijk} \times nh3\_kg_{ijk} +
\varepsilon_{ijk},\ \\
i=1,\ldots,I=6,\ j=1 \ldots,J=2, \ k=1,\ldots,n_{ij}.\\ (\varepsilon_{ijk})_{i,j,k} \textrm{ i.i.d
} \ \mathcal{N}(0,\sigma^2) \end{array}\right. 
$$

$ch4\_t_{ijk}$ représentes la valeur de la $k^{ème}$ mesure du $ch4\_t$ pour la $i^{ème}$ année et pour le $j^{ème}$ type d'EPCI.

```{r,  echo = FALSE }
complet<-lm(ch4_t ~ .^2 ,data=Datalog_[c(3,10,12, 14,15)])
summary(complet)
```

Nous supposons ensuite le modèle suivant sans interactions : 

$$
(M_2) 
\left\{\begin{array}{l} ch4\_t_{ijk}= \mu + \alpha_i + \beta_j + \theta \times nh3\_kg_{ijk} + \gamma \times n2o\_t_{ijk} + 

\varepsilon_{ijk},\ \\
i=1,\ldots,I=6,\ j=1 \ldots,J=2, \ k=1,\ldots,n_{ij}.\\ (\varepsilon_{ijk})_{i,j,k} \textrm{ i.i.d
}\mathcal{N}(0,\sigma^2) \end{array}\right. 
$$

```{r,  echo = FALSE,  include = FALSE}
mod_si<-lm(ch4_t ~ . ,data=Datalog_[c(3,10,12, 14,15)])
summary(mod_si)
```

Au vue des sorties des tests de student pour chaque coefficient, il semblerait que nous puissions supprimer certaines de ces interactions. Nous effectuons alors un test de sous modèle de Fisher pour voir si nous pouvons enlever les interactions.

```{r, echo=FALSE}
anova(mod_si,complet)
```

Notre p-valeur est très faible, nous ne pouvons pas supprimer toutes les interactions. Nous allons à la place utiliser un algorithme de sélection de variable pour réduire notre modèle.

Nous choissisons la méthode backward avec les critères BIC et AIC.

```{r, echo = FALSE}
stepAIC(complet,trace=F,direction="backward")
```

```{r, echo = FALSE}
stepAIC(complet,trace=F,direction="backward",k=log(nrow(Datalog_[c(3,10,12, 14,15)])))
```

Les deux algorithmes nous donne le même sous modèle :

$$
(M_3) 
\left\{\begin{array}{l} ch4\_t_{ijk}= \mu + \alpha_i + \beta_j + (a1 + a3_j)\times nh3\_kg_{ijk} + (b1 + b3_j)\times n2o\_t_{ijk} + \nu \times n2o\_t_{ijk} \times nh3\_kg_{ijk} +

\varepsilon_{ijk},\ \\
i=1,\ldots,I=6,\ j=1 \ldots,J=2, \ k=1,\ldots,n_{ij}.\\ (\varepsilon_{ijk})_{i,j,k} \textrm{ i.i.d
} \ \mathcal{N}(0,\sigma^2) \end{array}\right. 
$$

Nous avons supprimé 3 coefficients. Nous vérifions ce resultat avec un test de sous modèle.

```{r}
M3 = lm(ch4_t ~ annee_inv + nh3_kg + n2o_t + TypeEPCI + 
    nh3_kg:n2o_t + nh3_kg:TypeEPCI + n2o_t:TypeEPCI, data = Datalog_[c(3, 
    10, 12, 14, 15)])
```

```{r, echo = FALSE}
anova(M3, complet)
```

Notre p-valeur est bien supérieur à $0.05$ donc on ne rejette pas ce sous modèle.

Par curiosité, nous avons voulu supprimer certaines interactions manuellement. Nous avons trouvé que nous pouvions supprimer l'interaction entre $nh3\_kg$ et $n2o\_t$ et toujours avoir une p-valeur supérieure à $0.05$.

```{r, echo = FALSE}
anova(lm(formula = ch4_t ~ annee_inv + nh3_kg + n2o_t + TypeEPCI + 
     nh3_kg:TypeEPCI + n2o_t:TypeEPCI, data = Datalog_[c(3, 
    10, 12, 14, 15)]), complet)
```

Nous pourrions alors considérer le modèle final suivant : 

$$
(M_4) 
\left\{\begin{array}{l} ch4\_t_{ijk}= \mu + \alpha_i + \beta_j + (a1 + a3_j)\times nh3\_kg_{ijk} + (b1 + b3_j)\times n2o\_t_{ijk} +

\varepsilon_{ijk},\ \\
i=1,\ldots,I=6,\ j=1 \ldots,J=2, \ k=1,\ldots,n_{ij}.\\ (\varepsilon_{ijk})_{i,j,k} \textrm{ i.i.d
} \ \mathcal{N}(0,\sigma^2) \end{array}\right. 
$$

<!-- TODO : conclure quant au modèle que l'on garde au final -->



<!-- TODO (note indicative à retirer) : la partie MLG a été faite par Maxime (sur un fichier à part initialement, donc il peut y avoir des modifs à refaire) -->
## Modèle linéaire généralisé
<!-- TODO : titre agressif également -->

Nous allons dans cette section tenter d'expliquer le dépassement d'émission de méthane de $1000t$ par an en fonction de l'ammoniac, le protoxyde d'azote, le type d'EPCI et l'année par un modèle linéaire généralisé.

<!-- TODO (rien à faire a priori) : normalement, la fusion de nos codes devrait fonctionner -->
```{r, echo=F, eval=F}
#library(bestglm)
# TODO : voir si la libraire est vraiment nécessaire
```

On crée la nouvelle variable booléenne, valant 1 si le taux de méthane (\code{ch4_t}) est supérieur à $1000t$, 0 sinon.
<!-- TODO : normaliser la notation des variables (choisir entre dollardollar ou \code{}) -->

<!-- TODO : passer en echo = F (sûrement) -->
```{r, echo=T, eval=T}
# Tentative de mise en correspondance des codes

Data_mlg = Data_final[c(3,10,12,14,15)]

# Je crée une nouvelle variable qualitative (celle qui traduit méthane > 1000t)
Data_mlg$dep_met_1000 <- as.factor(as.numeric(Data_mlg$ch4_t>log(1000)))

summary(Data_mlg)

# Je retire la variable quantitative ch4_t
Data_mlg <- Data_mlg[c(1,2,4,5,6)]

summary(Data_mlg)
head(Data_mlg)
```

La variable \code{dep_met_1000} étant binaire, nous allons utiliser la régression logistique.

Dans un premier temps on crée le modèle complet avec interaction, modèle que l'on note $(\mathcal{M}_{GL_{1}})$ :

$$
\begin{equation*}
(\text{M}_{GL_{1}}) : 
\begin{cases}
\text{dep_met_1000}_i \sim \mathcal{B}(\pi_\theta(x_i)) \\
\\
\text{logit}[\pi_\theta(x_i)] = \mu  +  \theta_1\cdot\text{nh3_kg}_i  + \theta_2\cdot\text{n2o_t}_i  +  \gamma\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i  \\ 
  + (\beta_1  +  \beta_2\cdot\text{nh3_kg}_i ~ + \beta_3\cdot\text{n2o_t}_i + \beta_4\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}} \\
  + \sum_{k=1}^5 (\delta_{1k}  +  \delta_{2k}\cdot\text{nh3_kg}_i ~ + \delta_{3k}\cdot\text{n2o_t}_i + \delta_{4k}\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{annee}_i = 2014 + k} \\
  + \sum_{k=1}^5 (\kappa_{1k}  +  \kappa_{2k}\cdot\text{nh3_kg}_i ~ + \kappa_{3k}\cdot\text{n2o_t}_i + \kappa_{4k}\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i)\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}}\cdot\mathbb{1}_{\text{annee}_i = 2014 + k} \\
\end{cases}
\end{equation*}
$$

```{r, echo=T, eval=T}
modelcompletinter = glm(dep_met_1000~(.)^2, data=Data_mlg, family=binomial(link = "logit"))
summary(modelcompletinter)
```

On voit que beaucoup de variables ont une pvaleur > 0.05. On va alors s'intéresser à la simplification du modèle.
<!-- TODO : pourquoi pas réutiliser cette tournure de phrase pour la partie ANCOVA ? -->

```{r, echo=T, eval=T}
pseudoR2 = 1 - modelcompletinter$deviance/modelcompletinter$null.deviance
pseudoR2
```

Le $\text{pseudoR}^2$ vaut 0.73, ce qui est une valeur correcte.
<!-- TODO : je sais pas si on peut apporter plus de choses à cette remarque + la valeur du pseudoR2 a changé avec la fusion des TypeEPCI -->

```{r, echo = T, eval = F}
# Les bestglm ne fonctionnent pas
#bestglm(Data_mlg,family=binomial,IC="AIC")
#bestglm(Data_mlg,family=binomial,IC="BIC")
```

Ici, les fonctions \code{bestglm} ne fonctionnent pas, nous n'avons donc pas reporté leurs sorties dans le rapport.

```{r, echo = T, eval = T}
# Quelque chose semble ne pas fonctionner dans les step.backward
step.backward = step(modelcompletinter) # AIC
step.backward = step(modelcompletinter, direction="backward",k=log(nrow(Data_mlg))) # BIC
```

Le critère $AIC$ conserve le modèle sans l'interaction annee_inv:TypeEPCI, modèle que l'on note $(\text{M}_{GL_{2}})$.
Le critère $BIC$ conserve le modèle avec les variables nh3_kg, n2o_t, TypeEPCI, nh3_kg:n2o_t, modèle que l'on note $(\text{M}_{GL_{3}})$.


$$
\begin{equation*}
(\text{M}_{GL_{2}}) : 

\begin{cases}
\text{dep_met_1000}_i \sim \mathcal{B}(\pi_\theta(x_i)) \\

\\

\text{logit}[\pi_\theta(x_i)] = \mu  +  \theta_1\cdot\text{nh3_kg}_i  + \theta_2\cdot\text{n2o_t}_i  +  \gamma\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i  \\ 
  + (\beta_1  +  \beta_2\cdot\text{nh3_kg}_i ~ + \beta_3\cdot\text{n2o_t}_i  + \beta_4\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}} \\
  + \sum_{k=1}^5 (\delta_{1k}  +  \delta_{2k}\cdot\text{nh3_kg}_i ~ + \delta_{3k}\cdot\text{n2o_t}_i + \delta_{4k}\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{annee}_i = 2014 + k} \\

\end{cases}

\end{equation*}
$$


$$
\begin{equation*}
(\text{M}_{GL_{3}}) : 

\begin{cases}
\text{dep_met_1000}_i \sim \mathcal{B}(\pi_\theta(x_i)) \\

\\

\text{logit}[\pi_\theta(x_i)] = \mu  +  \theta_1\cdot\text{nh3_kg}_i  + \theta_2\cdot\text{n2o_t}_i  +  \gamma\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i  \\ 
  + (\beta_1  +  \beta_2\cdot\text{nh3_kg}_i ~ + \beta_3\cdot\text{n2o_t}_i + \beta_4\cdot\text{nh3_kg}_i\cdot\text{n2o_t}_i )\mathbb{1}_{\text{TypeEPCI}_i = \text{CC}} \\

\end{cases}

\end{equation*}

$$


```{r, echo = T, eval = T}
# Modèle 2
model2 = glm(dep_met_1000~annee_inv + nh3_kg + n2o_t + TypeEPCI + annee_inv:nh3_kg + 
    annee_inv:n2o_t + nh3_kg:n2o_t + nh3_kg:TypeEPCI + n2o_t:TypeEPCI ,data=Data_mlg, family=binomial(link = "logit"))
summary(model2)
```

On teste le sous-modèle $(\text{M}_{GL_{2}})$ par rapport au modèle complet avec interactions $(\text{M}_{GL_{1}})$.

```{r, echo = T, eval = T}
anova(model2, modelcompletinter, test="Chisq")
```

La pvaleur est >>0.05, on peut donc conserver le modèle $(\text{M}_{GL_{2}})$ au risque $5\%$.

```{r, echo = T, eval = T}
# TODO : ce bloc fonctionne pas, vérifier le noms du modèle
#pseudoR2 = 1 - modelinterred$deviance/modelinterred$null.deviance
pseudoR2
```

Le $\text{pseudoR}^2$ vaut 0.72, ce qui reste une valeur correcte (très légèrement en dessous du $\text{pseudoR}^2$ du modèle complet avec interactions).

```{r, echo = T, eval = T}
# Modèle 3
model3 = glm(dep_met_1000 ~ nh3_kg + n2o_t + TypeEPCI + nh3_kg:n2o_t,data=Data_mlg, family=binomial(link = "logit"))
summary(model3)
```

```{r, echo = T, eval = T}
anova(model3, modelcompletinter, test="Chisq")
```

Cependant, le test du sous-modèle $(\text{M}_{GL_{3}})$ vis-à-vis du modèle complet $(\text{M}_{GL_{1}})$ renvoie une pvaleur << 0.05.
On rejette donc le modèle $(\text{M}_{GL_{3}})$ au risque $5\%$.