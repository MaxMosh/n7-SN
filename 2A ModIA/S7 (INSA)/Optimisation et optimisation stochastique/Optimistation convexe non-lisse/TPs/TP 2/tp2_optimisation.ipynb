{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Reconstruction parcimonieuse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "On s'intéresse au problème\n",
    "\n",
    "$$\\hspace{5cm} (\\mathcal{P})\\quad \\min_{x\\in \\mathbb{R}^n}f(x) = \\frac{1}{2}\\Vert H x-y \\Vert_W^2+\\lambda \\Vert x \\Vert_1 $$\n",
    "\n",
    "avec $y\\in \\mathbb{R}^m$ une observation du signal à reconstruire, $H\\in \\mathcal{M}_{m,n}(\\mathbb{R})$, $W\\in \\mathcal{M}_{m}(\\mathbb{R})$ symétrique définie positive. La matrice $W$ introduit une pondération sur les composantes du résidu.\n",
    "\n",
    "**Question 1 :** Justifier la convexité de la fonctionnelle et donner un sous-gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Pkg.add(\"Plots\")\n",
    "using Plots\n",
    "\n",
    "# Construction du problème #\n",
    "############################\n",
    "\n",
    "# solution à reconstruire \n",
    "##########################\n",
    "dx=0.01;\n",
    "\n",
    "n=Int(1/dx);#+1;\n",
    "px=LinRange(0.,1.,n);\n",
    "xt=zeros(n,1);\n",
    "\n",
    "for i = 1:n\n",
    "    if (px[i] > 0.3 && px[i]< 0.6)\n",
    "        xt[i] = 2;         \n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "#observations\n",
    "#############\n",
    "nobs=1;\n",
    "m=Int(floor(n/nobs));\n",
    "var_obs=0.05;\n",
    "sigmaW=ones(m,1)+2.0*rand(Float64,(m,1));\n",
    "\n",
    "H=zeros(m,n);\n",
    "py=zeros(m,1);\n",
    "W=zeros(m,m);\n",
    "for i=1:m\n",
    "   H[i,(i-1)*nobs+1]=1;\n",
    "   py[i]=px[(i-1)*nobs+1]; \n",
    "   W[i,i]=sigmaW[i];\n",
    "end    \n",
    "y=H*xt+var_obs*randn(Float64,(m,1));\n",
    "\n",
    "\n",
    "p1=plot(px,xt,title=\"True solution\",label=[\"xt\"],lw=3);\n",
    "p2=scatter(py,y,title=\"Observations\",lw=3);\n",
    "plot(p1,p2,layout=(1,2),legend=false)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2 :** Proposer le calcul de l'évaluation de f et d'un sous-gradient de f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Fonction évaluant f en x\n",
    "function evalf(x,y,H,W,lambda) \n",
    "    # Insérer votre code\n",
    "    \n",
    "    # Fin insérer code\n",
    "end\n",
    "\n",
    "# Fonction évaluant un sous-gradient de f en x\n",
    "function subgradf(x,y,H,W,lambda) \n",
    "    # Insérer votre code\n",
    "   \n",
    "    # Fin insérer code\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3 :** Résoudre le problème en utilisant un algorithme de sous-gradient. Vous implanterez les trois stratégies de pas vues en cours. Vous afficherez les courbes de convergence de $f_{best}^k$. \n",
    "\n",
    "**Question 4 :** Quelle influence a le paramètre $\\lambda$ sur la convergence de l'algorithme et la qualité de la solution optimisée ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pkg.add(\"Plots\")\n",
    "using Plots\n",
    "\n",
    "#Initialisation\n",
    "x = zeros(n,1);\n",
    "xbest=x;\n",
    "i = 0;\n",
    "fbest =1000000; # $f_{best}^0$\n",
    "histo =[];# Suite des itérés f_{best}^k\n",
    "\n",
    "lambda=1e-2;\n",
    "\n",
    "pas=1;\n",
    "itermax=500;\n",
    "\n",
    "xp=x;\n",
    "while i < itermax\n",
    "    i = i + 1;\n",
    "    # Insérer votre code\n",
    "   \n",
    "    # Fin insérer code\n",
    "    \n",
    "    # Stockage\n",
    "    append!( histo, fbest)\n",
    "end\n",
    "#histo\n",
    "#Affichage des courbes de convergence\n",
    "#plotly();\n",
    "iter=1:itermax;\n",
    "plot(iter,histo,title=\"Convergence curve\",label=[\"f\"],lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[xt,xbest];\n",
    "\n",
    "plot(px,x,title=\"Reconstruction\",label=[\"True solution\" \"Optimized solution\"],lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question 5 :** On pose $h(x)=\\lambda \\Vert x\\Vert_1$ et $g(x)=\\frac{1}{2}\\Vert Hx-y\\Vert_W^2$. Donner une expression analytique de la fonction proximale de h et implanter cette fonction. Implanter la fonction $g$ ainsi que son gradient.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation de prox_h\n",
    "function proxh(x,lambda) \n",
    "# Insérer votre code\n",
    "   \n",
    "# Fin insérer code\n",
    "end\n",
    "\n",
    "#Evaluation de g\n",
    "function evalg(x,y,H,W)\n",
    "# Insérer votre code\n",
    "   \n",
    "# Fin insérer code\n",
    "end    \n",
    "\n",
    "\n",
    "#Evaluation du gradient de g\n",
    "function gradg(x,y,H,W)\n",
    "# Insérer votre code\n",
    "   \n",
    "# Fin insérer code\n",
    "end    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question 6 :** Résoudre le problème par la méthode du gradient proximal avec recherche linéaire pour le pas. Vous implanterez en prémabule la fonction de recherche linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction calculant le pas par recherche linéaire\n",
    "# Insérer votre code\n",
    "   \n",
    "# Fin insérer code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Initialisation\n",
    "x = zeros(n,1);\n",
    "xbest=x;\n",
    "i = 0;\n",
    "fbest =1000000; # $f_{best}^0$\n",
    "histo =[];# Suite des itérés f_{best}^k \n",
    "\n",
    "lambda0=100;\n",
    "itermax=500;\n",
    "beta=0.5;\n",
    "\n",
    "xp=x;\n",
    "\n",
    "while i < itermax\n",
    "    i = i + 1;\n",
    "    # Insérer votre code\n",
    "   \n",
    "    # Fin insérer code\n",
    "    \n",
    "    # Stockage\n",
    "    append!( histo, fbest)\n",
    "end\n",
    "#histo\n",
    "#Affichage des courbes de convergence\n",
    "plotly();\n",
    "iter=1:itermax;\n",
    "plot(iter,histo,title=\"Convergence curve\",label=[\"f\"],lw=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=[xt,xbest];\n",
    "\n",
    "plot(px,x,title=\"Reconstruction\",label=[\"True solution\" \"Optimized solution\"],lw=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "**Question 7 :** Evaluez la sensisibilité de l'algorithme aux différents paramètres : $\\lambda_0$, $\\beta$, itermax.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Julia 1.4.2",
   "language": "julia",
   "name": "julia-1.4"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
