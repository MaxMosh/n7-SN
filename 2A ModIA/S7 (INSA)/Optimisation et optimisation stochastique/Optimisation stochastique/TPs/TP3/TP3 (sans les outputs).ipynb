{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"display: flex; align-items: center; padding: 20px;\">\n",
    "    <div style=\"flex-grow: 1;\">\n",
    "        <h2><strong>MOSHFEGHI Maxime - PHUNG Anh Minh</strong></h2>\n",
    "    </div>\n",
    "    <div style=\"flex-shrink: 0; width: 40%;\">\n",
    "        <img src=\"https://hal.insa-toulouse.fr/public/Logo_INSAToulouse_blanc.png\" alt=\"Logo INSA Toulouse\" style=\"width: 90%; height: auto;\">\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **<div align = \"center\"> TP 2: Image segmentation with Neural Network </div>**\n",
    "\n",
    "## **Objective:**\n",
    "- Introduction to Pytorch (see previous tutorial notebook)\n",
    "- Define a simple neural network\n",
    "- Define a training procedure\n",
    "- Compare difference optimization methods\n",
    "- Enhance your coding skills\n",
    "\n",
    "We consider an image as a function from $\\Omega$ to $\\mathbb{R}$, where $\\Omega$ is a discretization of the space $[0,1]^2$. In this notebook, we suppose that we can partition $\\Omega$ into $2$ regular domains $\\Omega_1$ and $\\Omega_2 = \\Omega /  \\Omega_1$.\n",
    "\n",
    "On each domain, we suppose that the image has different textures. We will generate these textures as stationary Gaussian processes:\n",
    "- We will first generate a Gaussian noise. \n",
    "- We will then convolve this noise with a filter which describes the covariance matrix of the process. \n",
    "\n"
   ]
  },
  {
   "attachments": {
    "image_partition1.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAGQAAABkCAYAAABw4pVUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAA9hAAAPYQGoP6dpAAACFklEQVR4nO3c4W2CUBiF4WvjFPzuAA7RhAW6LFswBZ2iaX+ZWMSmyKecc/o+AyDw9rsXbfTwdnj/apDxsvcJ4CeCiCGIGIKIIYgYgoghiBiCiCGIGIKIIYgYgoghiBiCiCGIGIKIIYgYgoghiBiCiCGIGIKIIYgYgoghiBiCiCGIGIKIOVYebJjGkuP03ankOI4Wg1Td2HvNX/8/BTp8frxafR0hOc4wjX5BztLCnFcF201972W10uW12AZpLSvKmXWQ1vyjzM/fPoizpT+miCDuU3IpIkiSmCCOU7L06B4TJEVUEMcpmYsK0pp/lLggbub7CEEEXEaJDOK4bJ2jRAZx1Xen3CCOU9Ja8IS4/r8kNggTghIEEUMQMQQRQxAxsUF47EUJgoghiJjjfK11fYeb4mpC+u5kuyEmYMkSc/MLO0tT4rKcOU/4qglxvlAXq5cs9T1G+dz+4u49xP3CVW3a1NWnxVHJUxZR6pQ99ipEUTiHrUrfhyTckL3xxlBMTJCU6SwPknJj9hIzISkeEoQpuR8TIuYhQVw+FVbEhIghiBiCiCkPwv6xDRMipjQI07FdWZC9Y+z9+lU2/0xsyo1QsWlCiFHv7iDEeIzVQYZplI2hel5rrAqScMHqbm7qwzS2vjsR4cl+nRBiPN9VEOU94i+cz7211o7uF5CGz7LERAZxnvrIIM5ig7hOSWwQVwQRQxAx37rqfdCi46glAAAAAElFTkSuQmCC"
    },
    "image_processus1.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image_processus1.png](attachment:image_processus1.png)\n",
    "![image_partition1.png](attachment:image_partition1.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above is an example of an image and its partition $\\Omega_1$ and $\\Omega_2$. The objective is from the image on the left, train a neural network to predict the mask on the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La dataset que l'on va étudier aura la structure suivante :\n",
    "\n",
    "$$\n",
    "(\\text{image}_i, \\Omega_1^i)_i\n",
    "$$\n",
    "\n",
    "Nous allons entraîner un modèle :\n",
    "\n",
    "$$\n",
    "f_\\theta(\\text{image}) = \\Omega_1\n",
    "$$\n",
    "en minimisant :\n",
    "$$\n",
    "\\min_\\theta \\mathbb{E}\\displaystyle\\left[ l\\left( f_\\theta(\\text{image}), \\Omega_1 \\right) \\right]\n",
    "$$\n",
    "où $l$ est la fonction perte (loss).\n",
    "\n",
    "$$\n",
    "f_\\theta(\\text{image}) \\simeq \\mathbb{P}(\\text{\"appartenir à } \\Omega_1 \\text{ pour chaque pixel\"}) \n",
    "$$\n",
    "\n",
    "Les images seront générés grâce à des gaussiennes qui permettront de créer une image de base, puis une partie floue dans l'image. On rapelle la fonction de répartition d'une gaussienne à 2 dimensions :\n",
    "\n",
    "$$\n",
    "g(x,y) = \\cfrac{1}{2\\pi \\sigma^2}\\exp\\displaystyle\\left(-\\cfrac{x^2 + y^2}{2 \\sigma^2}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt                 # Importation de la bibliothèque matplotlib pour tracer des graphiques\n",
    "import torch                                    # Importation de la bibliothèque torch pour le calcul tensoriel                            \n",
    "import torch.optim as optim                     # Importation de la bibliothèque torch.optim pour les optimiseurs\n",
    "import torch.nn as nn                           # Importation de la bibliothèque torch.nn pour les réseaux de neurones    \n",
    "import torch.nn.functional as F                 # Importation de la bibliothèque torch.nn.functional pour les fonctions de coût\n",
    "import numpy as np                              # Importation de la bibliothèque numpy pour la manipulation de vecteurs et matrices\n",
    "from torch.optim import SGD, Adam, RMSprop      # Importation des optimiseurs SGD, Adam et RMSprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your device and data type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')       # Utilisation du GPU si disponible, sinon CPU\n",
    "dtype = torch.float32                                                       # Utilisation de flottants 32-bit\n",
    "factory_kwargs = {'device': device, 'dtype': dtype}                         # Dictionnaire des paramètres pour le type de données et le type de processeur\n",
    "\n",
    "print(\"factory_kwargs: \", factory_kwargs)                                # Affichage des paramètres     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)                                    # Initialisation du générateur aléatoire pour la reproductibilité des résultats "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Generating data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function will generate a batch of data with shape `(batch_size, 1, image_size, image_size)`\n",
    "Take a look at this function and try to understand what it does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(batch_size: int,                                 # Fonction pour générer des données           \n",
    "                  image_size: int = 128,                            # Taille de l'image\n",
    "                  sigma1: float = 1.,                               # Ecart type du premier processus Gaussien\n",
    "                  sigma2: float = 0.2,                              # Ecart type du second processus Gaussien\n",
    "                  sigma: float = 100,                               # Ecart type du processus Gaussien de l'image\n",
    "                  **factory_kwargs) -> torch.Tensor:                # Paramètres pour le type de données et le type de processeur\n",
    "    \n",
    "    # Defining a grid directly on device, without the need of calling `.to(device)` method,\n",
    "    # which is time consuming.\n",
    "    xs = torch.linspace(-image_size/2, image_size/2, image_size, **factory_kwargs)      # Définition d'une grille sur l'axe des abscisses \n",
    "    ys = torch.linspace(-image_size/2, image_size/2, image_size, **factory_kwargs)      # Définition d'une grille sur l'axe des ordonnées\n",
    "\n",
    "    # The type of x,y below is automatically in device and dtype of x, y.\n",
    "    x, y = torch.meshgrid(xs, ys, indexing='xy')                                     # Définition d'une grille 2D\n",
    "    \n",
    "    # Defining 4 Gaussian\n",
    "    g = torch.exp(-(x**2 + y**2) / (2 * sigma**2))                                      # Définition d'une gaussienne  \n",
    "    g = g / torch.sum(g)                                                            # Normalisation de la gaussienne            \n",
    "    \n",
    "    g1 = torch.exp(-(x**2 + y**2) / (2 * sigma1**2))                                # Définition d'une gaussienne \n",
    "    g1 = g1 / torch.sum(g1)                                                         # Normalisation de la gaussienne      \n",
    "\n",
    "    g2 = torch.exp(-(x**2 + y**2) / (2 * sigma2**2))                                # Définition d'une gaussienne\n",
    "    g2 = g2 / torch.sum(g2)                                                         # Normalisation de la gaussienne\n",
    "\n",
    "    g3 = torch.exp(-(x**2 + y**2) / (2 * 1**2))                                     # Définition d'une gaussienne\n",
    "    g3 = g3 / torch.sum(g3)                                                         # Normalisation de la gaussienne \n",
    "    \n",
    "    # We define a random smooth partition\n",
    "    b = torch.randn(batch_size,1,image_size,image_size, **factory_kwargs)           # Définition d'un tenseur de nombres aléatoires \n",
    "    gp = F.conv2d(b, g[None,None], padding = 'same')  # Convolution                 # Définition d'un tenseur de nombres aléatoires convolué avec la gaussienne\n",
    "\n",
    "    omega_1 = gp > 0                                                # Définition d'une partition aléatoire \n",
    "    omega_2 = ~omega_1                                              # Définition d'une partition aléatoire\n",
    "    \n",
    "    # We define two Gaussian random processes with different statistics\n",
    "    b1 = torch.randn(batch_size,1,image_size,image_size, **factory_kwargs)          # Définition d'un tenseur de nombres aléatoires\n",
    "    gp1 = F.conv2d(b1, g1[None,None], padding = 'same')                             # Définition d'un tenseur de nombres aléatoires convolué avec la gaussienne\n",
    "    \n",
    "    b2 = torch.randn(batch_size,1,image_size,image_size, **factory_kwargs)          # Définition d'un tenseur de nombres aléatoires\n",
    "    gp2 = F.conv2d(b2, g2[None,None], padding = 'same')                             # Définition d'un tenseur de nombres aléatoires convolué avec la gaussienne\n",
    "    \n",
    "    # Now we put each process at the right place\n",
    "    image = gp1 * omega_1 + gp2 * omega_2                                           # Définition d'une image\n",
    "    # We smooth the result to avoid having a jump at the interfaces of the partition\n",
    "    image =  F.conv2d(image, g3[None,None], padding = 'same')                       # Définition d'une image convoluée avec la gaussienne\n",
    "\n",
    "    # We normalize the image in to [0,1]\n",
    "    image = normalize_to_01(image)                                                  # Normalisation de l'image\n",
    "    \n",
    "    return image, omega_1.to(**factory_kwargs)                                      # Retourne l'image et la partition\n",
    "    \n",
    "\n",
    "def normalize_to_01(input: torch.Tensor) -> torch.Tensor:                           # Fonction pour normaliser les données\n",
    "    input -= input.amin(dim = (-2, -1), keepdim=True)                               # Normalisation des données\n",
    "    input /= input.amax(dim = (-2, -1), keepdim=True)                               # Normalisation des données \n",
    "    return input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data and its structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = generate_data(batch_size = 1,                                   # Génération des données                      \n",
    "                            image_size=128,                                     # Taille de l'image\n",
    "                            sigma1=0.2,                                         # Ecart type du premier processus Gaussien \n",
    "                            sigma2=10,                                          # Ecart type du second processus Gaussien\n",
    "                            sigma=15, **factory_kwargs) #la tolérance           # Ecart type du processus Gaussien de l'image\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 5))                                 # Création d'une figure\n",
    "axes[0].imshow(image[0].permute(1,2,0).detach().cpu().numpy())                  # Affichage de l'image\n",
    "axes[1].imshow(mask[0].permute(1,2,0).detach().cpu().numpy())                   # Affichage de la partition\n",
    "plt.show()                                                                      # Affichage de la figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"image.shape: \", image.shape)                                 # Affichage de la taille de l'image\n",
    "print(\"mask.shape: \", mask.shape)                                   # Affichage de la taille de la partition\n",
    "\n",
    "print(mask[0])                                                  # Affichage de la partition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more efficient way to generate a 2D Gaussian is in following, let have a look at this function and try to understand the difference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Influence des paramètres `sigma1`, `sigma2` et `sigma`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma1_liste = np.array([0.1, 0.5, 5, 20])\n",
    "sigma2_liste = np.array([1, 5, 10, 20])\n",
    "sigma_liste = np.array([1, 5, 10, 20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Influence de `sigma1`**\n",
    "\n",
    "Les autres paramètres seront fixés à `sigma2` = 10 et `sigma` = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "fig.suptitle('Influence de sigma1', fontsize=16)\n",
    "\n",
    "\n",
    "for sig1 in sigma1_liste :\n",
    "    image, mask = generate_data(batch_size = 1, \n",
    "                                image_size=128,\n",
    "                                sigma1=sig1,\n",
    "                                sigma2=10, \n",
    "                                sigma=15, **factory_kwargs) #la tolérance\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(image[0].permute(1,2,0).detach().cpu().numpy())\n",
    "    axes[1].imshow(mask[0].permute(1,2,0).detach().cpu().numpy())\n",
    "    plt.suptitle(f\"Pour sigma1 = {sig1}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :**\n",
    "\n",
    "Plus `sigma1` est grand, moins la partie de l'image (à gauche) correspondant à la partie jaune du masque est bruitée (on voit moins de petit point quand `sigma1` est grand). À l'oeil, on a tendance à mieux voir la différence entre la partie floue et celle qui ne l'est pas quand `sigma1` est petit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Influence de `sigma2`**\n",
    "\n",
    "Les autres paramètres seront fixés à `sigma1` = 0.2 et `sigma` = 15."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "fig.suptitle('Influence de sigma1', fontsize=16)\n",
    "\n",
    "\n",
    "for sig2 in sigma2_liste :\n",
    "    image, mask = generate_data(batch_size = 1, \n",
    "                                image_size=128,\n",
    "                                sigma1=0.2,\n",
    "                                sigma2=sig2, \n",
    "                                sigma=15, **factory_kwargs) #la tolérance\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(image[0].permute(1,2,0).detach().cpu().numpy())\n",
    "    axes[1].imshow(mask[0].permute(1,2,0).detach().cpu().numpy())\n",
    "    plt.suptitle(f\"Pour sigma2 = {sig2}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :**\n",
    "\n",
    "Plus `sigma2` est grand, mieux on arrive à faire la différence entre partie floue et partie non-floue. `sigma2` a donc une influence sur la force du floutage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Influence de `sigma`**\n",
    "\n",
    "Les autres paramètres seront fixés à `sigma1` = 0.2 et `sigma2` = 10."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 8))\n",
    "fig.suptitle('Influence de sigma', fontsize=16)\n",
    "\n",
    "\n",
    "for sig in sigma_liste :\n",
    "    image, mask = generate_data(batch_size = 1, \n",
    "                                image_size=128,\n",
    "                                sigma1=0.2,\n",
    "                                sigma2=10, \n",
    "                                sigma=sig, **factory_kwargs) #la tolérance\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "    axes[0].imshow(image[0].permute(1,2,0).detach().cpu().numpy())\n",
    "    axes[1].imshow(mask[0].permute(1,2,0).detach().cpu().numpy())\n",
    "    plt.suptitle(f\"Pour sigma = {sig}\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Commentaires :**\n",
    "\n",
    "Plus `sigma` est petit, plus il y a de discontinuité au sein de l'image entre partie floue et partie non-floue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(image_size, sigma, **factory_kwargs):                                              # Fonction pour générer une gaussienne\n",
    "    linspace = torch.linspace(-image_size/2, image_size/2, image_size, **factory_kwargs)        # Définition d'une grille sur l'axe des abscisses et des ordonnées\n",
    "    distance = linspace[None,:] ** 2 + linspace[:,None] ** 2                                    # Calcul de la distance\n",
    "    \n",
    "    # Defining 4 Gaussian\n",
    "    g = torch.exp(-distance / (2 * sigma**2))                                               # Définition d'une gaussienne\n",
    "    g = g / torch.sum(g)                                                                    # Normalisation de la gaussienne\n",
    "\n",
    "    return g                                                                                # Retourne la gaussienne"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define your neural network**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyFirtsCNN(nn.Module):                                            # Définition d'un réseau de neurones\n",
    "    def __init__(self, num_channels=16, kernel_size = 5, bias=True):    # Constructeur de la classe\n",
    "        super().__init__()                                              # Appel du constructeur de la classe mère \n",
    "\n",
    "        self.activation = nn.ReLU()                                     # Définition de la fonction d'activation\n",
    "        self.bn = nn.BatchNorm2d(num_channels)                          # Définition de la normalisation des données \n",
    "        self.bias = bias                                                # Initialisation du biais \n",
    "        self.kernel_size = kernel_size                                  # Initialisation de la taille du noyau                \n",
    "        self.pad = int((self.kernel_size - 1) / 2)                      # Initialisation du padding\n",
    "        self.conv1 = nn.Sequential(                                     # Définition de la première couche de convolution\n",
    "            nn.Conv2d(                                                  # Définition d'une couche de convolution\n",
    "                in_channels=1,                                          # Nombre de canaux en entrée \n",
    "                out_channels=num_channels,                              # Nombre de canaux en sortie\n",
    "                kernel_size=self.kernel_size,                           # Taille du noyau \n",
    "                stride=1,                                               # Pas de déplacement\n",
    "                padding=self.pad,                                       # Padding \n",
    "                bias=bias,                                              # Biais\n",
    "            ),\n",
    "            self.activation,                                            # Fonction d'activation\n",
    "            self.bn                                                     # Normalisation des données\n",
    "        )\n",
    "        self.conv2 = nn.Sequential(                                     # Définition de la deuxième couche de convolution\n",
    "            nn.Conv2d(                                                  # Définition d'une couche de convolution\n",
    "                in_channels=num_channels,                               # Nombre de canaux en entrée\n",
    "                out_channels=num_channels,                              # Nombre de canaux en sortie\n",
    "                kernel_size=self.kernel_size,                           # Taille du noyau\n",
    "                stride=1,                                               # Pas de déplacement\n",
    "                padding=self.pad,                                       # Padding\n",
    "                bias=self.bias,                                         # Biais\n",
    "            ),\n",
    "            self.activation,                            # Fonction d'activation \n",
    "            self.bn                                     # Normalisation des données\n",
    "        )\n",
    "        self.conv3 = nn.Sequential(                      # Définition de la troisième couche de convolution\n",
    "            nn.Conv2d(                                  # Définition d'une couche de convolution\n",
    "                in_channels=num_channels,               # Nombre de canaux en entrée\n",
    "                out_channels=num_channels,              # Nombre de canaux en sortie\n",
    "                kernel_size=self.kernel_size,           # Taille du noyau\n",
    "                stride=1,                               # Pas de déplacement\n",
    "                padding=self.pad,                       # Padding\n",
    "                bias=self.bias,                         # Biais\n",
    "            ),\n",
    "            self.activation,                            # Fonction d'activation\n",
    "            self.bn                                     # Normalisation des données\n",
    "        )\n",
    "\n",
    "        self.out = nn.Conv2d(                           # Définition de la couche de sortie\n",
    "                in_channels=num_channels,               # Nombre de canaux en entrée\n",
    "                out_channels=1,                         # Nombre de canaux en sortie\n",
    "                kernel_size=self.kernel_size,           # Taille du noyau\n",
    "                stride=1,                               # Pas de déplacement\n",
    "                padding=self.pad,                       # Padding\n",
    "                bias=self.bias,                         \n",
    "        )\n",
    "\n",
    "    def forward(self, x):                               # Fonction pour la propagation avant\n",
    "        x1 = self.conv1(x)                              # Propagation de l'entrée dans la première couche de convolution\n",
    "        x2 = self.conv2(x1)                             # Propagation de l'entrée dans la deuxième couche de convolution\n",
    "        x3 = self.conv3(x2)                              # Propagation de l'entrée dans la troisième couche de convolution    \n",
    "        output = torch.sigmoid(self.out(x3))            # Propagation de l'entrée dans la couche de sortie\n",
    "        return output                                   # Retourne la sortie\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question: How many layers do we have in the network? What are the activation functions?**\n",
    "\n",
    "\n",
    "**Réponse :**\n",
    "\n",
    "Le réseau de neurones (`MyFirstCNN`) est constitué de 3 couches que l'on détaille ci-dessous. La fonction d'activation utilisée est la fonction ReLU.\n",
    "\n",
    "\n",
    "- 1. Convolutional Layer 1 (conv1):\n",
    "\n",
    "Input Channels: 1 (assuming grayscale images)\n",
    "Output Channels: num_channels\n",
    "Kernel Size: kernel_size\n",
    "Activation Function: ReLU\n",
    "Batch Normalization is applied after the ReLU activation.\n",
    "\n",
    "\n",
    "\n",
    "- 2. Convolutional Layer 2 (conv2):\n",
    "\n",
    "Input Channels: num_channels\n",
    "Output Channels: num_channels\n",
    "Kernel Size: kernel_size\n",
    "Activation Function: ReLU\n",
    "Batch Normalization is applied after the ReLU activation.\n",
    "\n",
    "\n",
    "\n",
    "- 3. Convolutional Layer 3 (conv3):\n",
    "\n",
    "Input Channels: num_channels\n",
    "Output Channels: num_channels\n",
    "Kernel Size: kernel_size\n",
    "Activation Function: ReLU\n",
    "Batch Normalization is applied after the ReLU activation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question : Explain why we have a `sigmoid` activation at the end of the network? Write the training optimization problem.**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** \n",
    "\n",
    "La fonction d'activation sigmoïde est utilisée à la fin du réseau pour les problèmes de classification binaire afin d'écraser la sortie du réseau dans l'intervalle [0, 1]. \n",
    "\n",
    "Cette fonction est particulièrement adaptée lorsque l'objectif est d'interpréter la sortie comme une probabilité indiquant la probabilité d'appartenir à une classe. \n",
    "\n",
    "Dans notre cas, l'idée étant de détecter les parties floues et non floues, uitliser une fonction d'activation sigmoïde nous permet d'obtenir une probabilité de faire partie du domaine d'intérêt (floue ou non-floue, selon la manière dont elle est implémentée).\n",
    "\n",
    "Mathématiquement, elle est définie comme suit :\n",
    "$$\n",
    "\\text{sigmoid}(x) = \\frac{1}{1 + e^{-x}}\n",
    "\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyFirtsCNN(num_channels=16, kernel_size = 5)        # Instanciation du réseau de neurones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let see how many parameters you have in your model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):                                                        # Fonction pour compter le nombre de paramètres\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)            # Retourne le nombre de paramètres\n",
    "\n",
    "print(\"Number of parameters: \", count_parameters(model))                            # Affichage du nombre de paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# By default, the model (i.e., the trainable parameters) is stored in CPU\n",
    "print(next(model.parameters()).device)                                      # Affichage du type de processeur utilisé pour le modèle \n",
    "# You have to push your to GPU if you want to use GPU\n",
    "model = model.to(device)                                                    # Utilisation du GPU si disponible, sinon CPU \n",
    "print(next(model.parameters()).device)                                      # Affichage du type de processeur utilisé pour le modèle    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Question: Verify your model output shape? The link with the input shape?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Input shape: \", image.shape)                     # Affichage de la taille de l'entrée\n",
    "print(\"Output shape: \", model.forward(image).shape)     # Affichage de la taille de la sortie\n",
    "(model.forward(image) != model.forward(image)).sum()        # Affichage du nombre de valeurs différentes entre la sortie et l'entrée"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Réponse :** \n",
    "\n",
    "L'input et l'output ont même taille : on a fait du 0-padding pour obtenir ces deux éléments de même taille."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Define your optimization algorithm**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimization algorithms are defined in `torch.optim`. We need to pass all the trainable parameters to the optimizer, along with other hyperparameters such as the learning rate, ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001)           # Définition de l'optimiseur SGD "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Training the model**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define your training hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm                          # Importation de la fonction tqdm pour afficher une barre de progression "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how to train a neural network. Look at these line of code carefully and understand what is does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train_iteration = 10000                 # Nombre d'itérations\n",
    "batch_size = 8                              # Taille du batch\n",
    "display_prediction_every = 1000             # Affichage de la prédiction toutes les 1000 itérations \n",
    "image_size = 128                            # Taille de l'image\n",
    "sigma1 = 0.2                                # Ecart type du premier processus Gaussien \n",
    "sigma2 = 1.2                                # Ecart type du second processus Gaussien \n",
    "sigma = image_size / 5                      # Ecart type du processus Gaussien de l'image\n",
    "\n",
    "\n",
    "t = tqdm(range(num_train_iteration))        # Affichage de la barre de progression\n",
    "avg_loss = 0                                # Initialisation de la loss moyenne\n",
    "loss_tracking = []                          # Initialisation de la loss tracking \n",
    "\n",
    "for i in t:                            # Boucle d'itération\n",
    "    x, omega_1 = generate_data(batch_size, image_size, sigma1, sigma2, sigma, **factory_kwargs) # Génération des données \n",
    "\n",
    "    # Step 1: Réinitialise les gradients à zéro.\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Step 2: Passe les données à travers le modèle pour obtenir les prédictions.\n",
    "    predicted_omega_1 = model(x)\n",
    "\n",
    "    # Step 3: Calcule la loss entre les prédictions et les étiquettes réelles.\n",
    "    loss = torch.mean((predicted_omega_1 - omega_1) ** 2 )\n",
    "\n",
    "    # Step 4: calculer les gradients(Effectue la rétropropagation des gradients.)\n",
    "    loss.backward()\n",
    "\n",
    "    # Step 5: mettre à jour les paramètres(Applique une étape d'optimisation pour mettre à jour les paramètres du modèle.)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Tracking \n",
    "    avg_loss += loss.item()         # Calcul de la loss moyenne\n",
    "    loss_tracking.append(avg_loss / (i + 1))        # Calcul de la loss tracking\n",
    "    t.set_description(f\"Iteration: {i + 1}, Loss: {avg_loss / (i + 1):.4e}\")        # Affichage de la loss moyenne\n",
    "\n",
    "    if (i + 1) % display_prediction_every == 0:                             # Affichage de la prédiction toutes les 1000 itérations\n",
    "        # Turn off the gradient tracking for better performance\n",
    "        # since we don't need to track the gradients for this step\n",
    "        with torch.no_grad():                                               # Désactivation du gradient pour une meilleure performance \n",
    "            fig, axes = plt.subplots(1, 3, figsize=(15, 5))                 # Création d'une figure \n",
    "            \n",
    "            axes[0].imshow(x[0,0].detach().cpu().numpy())                   # Affichage de l'image\n",
    "            axes[0].set_title(\"Input image\")                                # Affichage du titre de l'image \n",
    "\n",
    "            axes[1].imshow(omega_1[0,0].detach().cpu().numpy())             # Affichage de la partition\n",
    "            axes[1].set_title(\"True mask\")                                  # Affichage du titre de la partition\n",
    "\n",
    "            axes[2].imshow(predicted_omega_1[0,0].detach().cpu().numpy())       # Affichage de la prédiction     \n",
    "            axes[2].set_title(\"Predicted mask\")                                 # Affichage du titre de la prédiction\n",
    "            plt.suptitle(\"Iteration: {}\".format(i + 1))                         # Affichage du titre de la figure\n",
    "            plt.show()                                                # Affichage de la figure                          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Question: What is the loss function used here? If you have any idea about the loss function, don't hesitate to change it.\n",
    "\n",
    "### Réponse: La fonction de perte utilisée semble être la Mean Squared Error (MSE) entre les prédictions et les étiquettes réelles.\n",
    "Mathématiquement, cela s'exprime comme suit : \n",
    "\n",
    "Si nous avons N prédictions $ y_{\\text{pred}}^{(i)} $ correspondantes à N étiquettes réelles $ y_{\\text{true}}^{(i)} $, alors la MSE est donnée par :\n",
    "\n",
    "\n",
    "$$\\text{MSE} = \\frac{1}{N} \\sum_{i=1}^{N} (y_{\\text{pred}}^{(i)} - y_{\\text{reel}}^{(i)})^2$$\n",
    "Cela représente la moyenne des carrés des différences entre chaque prédiction et sa valeur réelle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the evolution of the average loss over the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(loss_tracking)             # Affichage de la loss tracking\n",
    "plt.xlabel(\"Iteration\")             # Affichage de l'axe des abscisses\n",
    "plt.ylabel(\"Loss\")                  # Affichage de l'axe des ordonnées\n",
    "\n",
    "plt.show()                          # Affichage de la figure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are satisfied with the result, save your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = model.state_dict()             # Récupération des paramètres du modèle\n",
    "torch.save(state_dict, \"best_model.pt\")     # Sauvegarde des paramètres du modèle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical section: Train your best model\n",
    "See the influence of each parameter:\n",
    "**- `sigma1`, `sigma2` and `sigma` are parameters which difine the difficulty of the problem.**\n",
    "\n",
    "And\n",
    "\n",
    "**- Try different optimizers and learning rates (see `torch.optim` in [this link](https://pytorch.org/docs/stable/optim.html#algorithms) ). Compare the performance.**\n",
    "\n",
    "\n",
    "**Réponse :**\n",
    "Expérimentez avec différents optimiseurs disponibles dans PyTorch, tels que Adam, SGD, RMSProp, NAdam, etc. Chaque optimiseur a ses avantages selon la nature du problème.\n",
    "Comparez les performances des différents optimiseurs.\n",
    "\n",
    "\n",
    "\n",
    "**- What happens if the learning rate is too large? too small?**\n",
    "\n",
    "**Réponse :**\n",
    "- Un learning rate trop grand peut entraîner une divergence de la loss.\n",
    "- Les calculs effectués lors de la rétropropagation peuvent dépasser les limites numériques des représentations en virgule flottante \n",
    "- Il peut entraîner des oscillations autour du minimum global ou local de la fonction de perte. Au lieu de converger de manière régulière vers la solution optimale, l'algorithme peut sauter d'un côté à l'autre de la vallée de la loss, rendant la convergence inefficace voire impossible.\n",
    "En conclusion:\n",
    "Pour éviter ces problèmes, il est souvent recommandé de commencer par des learning rates plus petits et d'augmenter progressivement si la convergence est trop lente et d'ajuster dynamiquement le learning rate au fur et à mesure de l'entraînement en fonction de la performance du modèle.\n",
    "\n",
    "**Learning Rates:**\n",
    "- Essayez différentes valeurs de taux d'apprentissage pour chaque optimiseur.\n",
    "- Étudiez l'effet des taux d'apprentissage qui sont trop grands ou trop petits. Un taux d'apprentissage trop grand peut entraîner un dépassement, tandis qu'un taux d'apprentissage trop petit peut entraîner une convergence lente ou rester bloqué dans des minima locaux.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**- How to evaluate the performance of your model?**\n",
    "\n",
    "**Réponse :**\n",
    "\n",
    "- Courbe de loss : Checker la courbe de perte d'entraînement. Une diminution de la perte indique que le modèle apprend et converge vers une solution. Cependant, soit prudent en cas de surapprentissage si la perte sur les données de validation commence à augmenter alors que la perte d'entraînement diminue. Évaluons le modèle sur un ensemble de données de validation séparé. Cela nous donne une indication de la capacité du modèle à généraliser sur des données non vues. Si la perte de validation est nettement supérieure à la perte d'entraînement, cela peut indiquer un surapprentissage.\n",
    "\n",
    "**- With a limit training time, try to train your best model.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer SGD, Adam, RMSprop and NAdam in learning_rates 0.001 0.01 0.1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Commentaires :\n",
    "\n",
    "Les sorties ci-dessous nous montrent que la fonction loss est la meilleure dans le cas de l'optimizer Adam avec un learning rate de 0.001. En effet, on obtient une loss de 0.003 avec Adam à itération finale. À titre de comparaison, la valeur de la fonction loss est deux fois plus grande avec le même optimizer mais avec un learning rate de 0.1. Autrement, en prenant d'optimizer SGD et en prenant le learling rate de 0.01, la fonction loss à l'itération finale est de 0.018, soit plus de 6 fois plus grande que la loss obtenue avec Adam."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [torch.optim.SGD, torch.optim.Adam, torch.optim.RMSprop, torch.optim.NAdam]            # Définition des optimiseurs à tester\n",
    "learning_rates = [0.001, 0.01, 0.1]                                                                 # Définition des learning rates à étudier\n",
    "for optimizer_class in optimizers:                                                                  # Boucle d'itération sur les optimiseurs à tester\n",
    "    for learning_rate in learning_rates:                                                            # Boucle d'itération sur les learning rates à tester\n",
    "        optimizer = optimizer_class(model.parameters(), lr=learning_rate)                           # Définition de l'optimiseur\n",
    "        print(\"Optimizer: \", optimizer)                                                             # Affichage de l'optimiseur\n",
    "        num_train_iteration = 10000                                                                 # Nombre d'itérations \n",
    "        batch_size = 8                                                                              # Taille du batch    \n",
    "        display_prediction_every = 1000                                                             # Affichage de la prédiction toutes les 1000 itérations                                                             \n",
    "        image_size = 128                                                                            # Taille de l'image\n",
    "        sigma1 = 0.2                                                                                # Ecart type du premier processus Gaussien\n",
    "        sigma2 = 1.2                                                                                # Ecart type du second processus Gaussien\n",
    "        sigma = image_size / 5                                                                  # Ecart type du processus Gaussien de l'image\n",
    "\n",
    "\n",
    "        t = tqdm(range(num_train_iteration))                                                    # Affichage de la barre de progression\n",
    "        avg_loss = 0                                                                            # Initialisation de la loss moyenne\n",
    "        loss_tracking = []                                                                      # Initialisation de la loss tracking\n",
    "\n",
    "        for i in t:                                                                # Boucle d'itération\n",
    "            x, omega_1 = generate_data(batch_size, image_size, sigma1, sigma2, sigma, **factory_kwargs)         # Génération des données\n",
    "\n",
    "            # Step 1: Réinitialise les gradients à zéro.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Step 2: Passe les données à travers le modèle pour obtenir les prédictions.\n",
    "            predicted_omega_1 = model(x)\n",
    "\n",
    "            # Step 3: Calcule la loss entre les prédictions et les étiquettes réelles.\n",
    "            loss = torch.mean((predicted_omega_1 - omega_1) ** 2 )\n",
    "\n",
    "            # Step 4: calculer les gradients(Effectue la rétropropagation des gradients.)\n",
    "            loss.backward()\n",
    "\n",
    "            # Step 5: mettre à jour les paramètres(Applique une étape d'optimisation pour mettre à jour les paramètres du modèle.)\n",
    "            optimizer.step()\n",
    "\n",
    "            # Tracking \n",
    "            avg_loss += loss.item()                                                             # Calcul de la loss moyenne\n",
    "            loss_tracking.append(avg_loss / (i + 1))                                            # Calcul de la loss tracking             \n",
    "            t.set_description(f\"Iteration: {i + 1}, Loss: {avg_loss / (i + 1):.4e}\")            # Affichage de la loss moyenne\n",
    "\n",
    "            if (i + 1) % display_prediction_every == 0:                                         # Affichage de la prédiction toutes les 1000 itérations\n",
    "                # Turn off the gradient tracking for better performance\n",
    "                # since we don't need to track the gradients for this step\n",
    "                with torch.no_grad():                                                           # Désactivation du gradient pour une meilleure performance\n",
    "                    fig, axes = plt.subplots(1, 3, figsize=(15, 5))                             # Création d'une figure\n",
    "                    \n",
    "                    axes[0].imshow(x[0,0].detach().cpu().numpy())                               # Affichage de l'image\n",
    "                    axes[0].set_title(\"Input image\")                                            # Affichage du titre de l'image\n",
    "\n",
    "                    axes[1].imshow(omega_1[0,0].detach().cpu().numpy())                         # Affichage de la partition\n",
    "                    axes[1].set_title(\"True mask\")                                              # Affichage du titre de la partition\n",
    "\n",
    "                    axes[2].imshow(predicted_omega_1[0,0].detach().cpu().numpy())               # Affichage de la prédiction\n",
    "                    axes[2].set_title(\"Predicted mask\")                                         # Affichage du titre de la prédiction\n",
    "                    plt.suptitle(\"Iteration: {}\".format(i + 1))                                 # Affichage du titre de la figure\n",
    "                    plt.show()                                                                  # Affichage de la figure\n",
    "        # Imprimer la dernière valeur de perte pour chaque test\n",
    "        print(f\"Dernière valeur de perte pour {optimizer_class.__name__} avec learning rate {learning_rate}: {loss_tracking[-1]}\")      # Affichage de la dernière valeur de perte pour chaque test\n",
    "        plt.plot(loss_tracking)                                                                                                # Affichage de la loss tracking\n",
    "        plt.xlabel(\"Iteration\")                                                                                           # Affichage de l'axe des abscisses\n",
    "        plt.ylabel(\"Loss\")                                                                                          # Affichage de l'axe des ordonnées\n",
    "\n",
    "        plt.show()                                                                                        # Affichage de la figure"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
